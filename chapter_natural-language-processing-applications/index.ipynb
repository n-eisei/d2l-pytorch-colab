{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "266cd7f2",
      "metadata": {},
      "source": "\n# 自然言語処理: アプリケーション\n\n:label: `chap_nlp_app`\n\nテキスト シーケンスでトークンを表現し、その表現を :numref: `chap_nlp_pretrain`でトレーニングする方法を説明しました。このような事前トレーニングされたテキスト表現は、さまざまな下流の自然言語処理タスクのさまざまなモデルに供給できます。\n\n実際、これまでの章では、深層学習アーキテクチャを説明するためだけに、*事前トレーニングを行わない*いくつかの自然言語処理アプリケーションについてすでに説明しました。たとえば、 :numref: `chap_rnn`では、RNN を利用して小説のようなテキストを生成する言語モデルを設計しました。 :numref: `chap_modern_rnn`および :numref: `chap_attention-and-transformers`では、RNN と機械翻訳用のアテンション メカニズムに基づいたモデルも設計しました。\n\nただし、本書はそのようなアプリケーションすべてを包括的にカバーすることを意図したものではありません。代わりに、私たちは*自然言語処理の問題に対処するために言語の (深い) 表現学習を適用する方法に*焦点を当てています。この章では、事前トレーニングされたテキスト表現を前提として、2 つの一般的で代表的なダウンストリーム自然言語処理タスク、つまり単一テキストとテキスト ペアの関係をそれぞれ分析する感情分析と自然言語推論について説明します。 \n\n![](../img/nlp-map-app.svg) :label: `fig_nlp-map-app`\n\n :numref: `fig_nlp-map-app`に示されているように、この章では、MLP、CNN、RNN、attention などのさまざまなタイプの深層学習アーキテクチャを使用して自然言語処理モデルを設計する基本的な考え方を説明することに重点を置いています。 :numref: `fig_nlp-map-app`で、いずれかのアプリケーションの任意のアーキテクチャと事前トレーニング済みのテキスト表現を組み合わせることが可能ですが、ここでは代表的な組み合わせをいくつか選択します。具体的には、センチメント分析用の RNN と CNN に基づいた一般的なアーキテクチャを調査します。自然言語推論の場合、テキスト ペアを分析する方法を示すためにアテンションと MLP を選択します。最後に、シーケンス レベル (単一テキスト分類とテキスト ペア分類) やトークン レベル (テキスト タグ付けと質問応答など) など、幅広い自然言語処理アプリケーション向けに事前トレーニング済み BERT モデルを微調整する方法を紹介します。 ）。具体的な経験例として、自然言語推論用に BERT を微調整します。\n\n :numref: `sec_bert`で紹介したように、BERT では、幅広い自然言語処理アプリケーションに対して最小限のアーキテクチャ変更が必要です。ただし、この利点には、ダウンストリーム アプリケーション向けに膨大な数の BERT パラメータを微調整するという代償が伴います。スペースまたは時間が限られている場合は、MLP、CNN、RNN、および注意に基づいて作成されたモデルの方が実現可能です。以下では、センチメント分析アプリケーションから始めて、それぞれ RNN と CNN に基づくモデル設計を説明します。\n\n :begin_tab:toc\n- [感情分析とデータセット](sentiment-analysis-and-dataset.ipynb)\n- [感情分析-rnn](sentiment-analysis-rnn.ipynb)\n- [感情分析-CNN](sentiment-analysis-cnn.ipynb)\n- [自然言語推論とデータセット](natural-language-inference-and-dataset.ipynb)\n- [自然言語推論-注意](natural-language-inference-attention.ipynb)\n- [微調整-バート](finetuning-bert.ipynb)\n- [自然言語推論バート](natural-language-inference-bert.ipynb):end_tab:\n"
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}