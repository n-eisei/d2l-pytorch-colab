{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1376e83b",
      "metadata": {},
      "source": "\n# 最新の畳み込みニューラル ネットワーク\n\n:ラベル: `chap_modern_cnn`\n\n CNN を接続する基本を理解したところで、最新の CNN アーキテクチャを見てみましょう。刺激的な新しいデザインが多数追加されているため、このツアーは必然的に未完成となります。それらの重要性は、視覚タスクに直接使用できるだけでなく、追跡 :cite: `Zhang.Sun.Jiang.ea.2021` 、セグメンテーション :cite: などのより高度なタスクの基本的な特徴ジェネレーターとしても機能するという事実に由来します。 `Long.Shelhamer.Darrell.2015` 、オブジェクト検出 :cite: `Redmon.Farhadi.2018` 、またはスタイル変換 :cite: `Gatys.Ecker.Bethge.2016` 。この章では、ほとんどのセクションが重要な CNN アーキテクチャに対応しています。このアーキテクチャは、ある時点 (または現在) で多くの研究プロジェクトや展開されたシステムが構築された基本モデルでした。これらの各ネットワークは、一時的には有力なアーキテクチャであり、その多くは、2010 年以来コンピューター ビジョンにおける教師あり学習の進歩のバロメーターとして機能してきた[ImageNet コンペティション](https://www.image-net.org/challenges/LSVRC/)で優勝または準優勝でした。Transformers が CNN に取って代わり始めたのはつい最近のことです。 :citet: `Dosovitskiy.Beyer.Kolesnikov.ea.2021`で始まり、Swin Transformer :cite: `liu2021swin`が続きます。この開発については、:ref: `chap_attention-and-transformers`の章で後ほど説明します。\n\n*ディープ*ニューラル ネットワークの考え方は非常にシンプル (多数のレイヤーを積み重ねる) ですが、パフォーマンスはアーキテクチャやハイパーパラメーターの選択によって大きく異なります。この章で説明するニューラル ネットワークは、直観、いくつかの数学的洞察、および多くの試行錯誤の産物です。これらのモデルを年代順に紹介しますが、これは部分的には歴史の感覚を伝え、この分野がどこに向かっているのかについて独自の直観を形成し、独自のアーキテクチャを開発できるようにするためでもあります。たとえば、この章で説明するバッチ正規化と残差接続は、深いモデルのトレーニングと設計のための 2 つの一般的なアイデアを提供し、その後、どちらもコンピューター ビジョンを超えたアーキテクチャにも適用されています。\n\n最新の CNN のツアーは AlexNet から始まります (引用: `Krizhevsky.Sutskever.Hinton.2012` )。これは、大規模なビジョンの課題において従来のコンピュータ ビジョン手法を打ち負かすために導入された最初の大規模ネットワークです。 VGG ネットワーク :cite: `Simonyan.Zisserman.2014` 。要素の繰り返しブロックを多数利用します。入力に対してニューラル ネットワーク全体をパッチ単位で畳み込むネットワーク イン ネットワーク (NiN) :cite: `Lin.Chen.Yan.2013` ;マルチブランチ畳み込みネットワークを使用する GoogLeNet :cite: `Szegedy.Liu.Jia.ea.2015` ;残差ネットワーク (ResNet) :cite: `He.Zhang.Ren.ea.2016` 、これは依然としてコンピューター ビジョンで最も人気のある既製アーキテクチャの一部です。 ResNext は、接続がまばらな場合、:cite: `Xie.Girshick.Dollar.ea.2017`をブロックします。残差アーキテクチャの一般化については、DenseNet :cite: `Huang.Liu.Van-Der-Maaten.ea.2017`を参照してください。時間の経過とともに、座標シフト (ShiftNet) :cite: `wu2018shift`など、効率的なネットワークのための多くの特別な最適化が開発されました。これは、MobileNet v3 :cite: `Howard.Sandler.Chu.ea.2019`などの効率的なアーキテクチャの自動検索で最高潮に達しました。また、この章で後ほど説明する RegNetX/Y につながる :citet: `Radosavovic.Kosaraju.Girshick.ea.2020`の半自動設計探索も含まれています。この研究は、効率的な設計空間を探索する際に、強引な計算と実験者の創意工夫を組み合わせる道を提供するという点で有益です。 :citet: `liu2022convnet`の成果も注目に値します。これは、トレーニング手法 (オプティマイザー、データ拡張、正則化など) が精度の向上に極めて重要な役割を果たすことを示しています。また、計算とデータの増加を考慮すると、畳み込みウィンドウのサイズなど、長年保持されてきた仮定を再検討する必要がある可能性があることも示しています。この章では、この点とさらに多くの質問について、今後説明していきます。\n\n :begin_tab:toc\n- [アレックスネット](alexnet.ipynb)\n- [vgg](vgg.ipynb)\n- [にん](nin.ipynb)\n- [グーグルネット](googlenet.ipynb)\n- [バッチノルム](batch-norm.ipynb)\n- [レスネット](resnet.ipynb)\n- [デンスネット](densenet.ipynb)\n- [cnn-デザイン](cnn-design.ipynb):end_tab:\n"
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}