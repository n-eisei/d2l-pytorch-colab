{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "72e19bff",
      "metadata": {},
      "source": "\n# ハイパーパラメータの最適化\n\n:label: `chap_hyperopt`\n\n **Aaron Klein** ( *Amazon* )、 **Matthias Seeger** ( *Amazon* )、および**Cedric Archambeau** ( *Amazon* )\n\nすべての機械学習モデルのパフォーマンスは、そのハイパーパラメーターに依存します。これらは、学習アルゴリズムまたは基礎となる統計モデルの構造を制御します。ただし、実際にはハイパーパラメータを選択する一般的な方法はありません。代わりに、ハイパーパラメータは多くの場合、試行錯誤の方法で設定されたり、場合によってはデフォルト値のままになったりして、最適化されていない一般化につながります。\n\nハイパーパラメータの最適化は、この問題を最適化問題としてキャストすることにより、この問題に対する体系的なアプローチを提供します。適切なハイパーパラメータのセットは、（少なくとも）検証エラーを最小限に抑える必要があります。機械学習で生じる他のほとんどの最適化問題と比較すると、ハイパーパラメーターの最適化は入れ子になっており、反復ごとに機械学習モデルのトレーニングと検証が必要になります。\n\nこの章では、まずハイパーパラメータ最適化の基本を紹介します。また、元の目的関数の評価コストの低いプロキシを活用することで、ハイパーパラメータ最適化の全体的な効率を向上させる最近の進歩についても紹介します。この章の最後には、最先端のハイパーパラメータ最適化手法を適用して、独自の機械学習アルゴリズムのハイパーパラメータを最適化できるようになります。\n\n :begin_tab:toc\n- [ハイパーオプトイントロ](hyperopt-intro.ipynb)\n- [ハイパーオプトAPI](hyperopt-api.ipynb)\n-  [rs-async.md](rs-async.md.ipynb)\n- [イントロ](sh-intro.ipynb)\n- [sh-async](sh-async.ipynb) :end_tab:\n"
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}