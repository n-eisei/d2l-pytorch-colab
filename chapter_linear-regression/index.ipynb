{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "01ff8565",
      "metadata": {},
      "source": [
        "\n",
        "# 回帰用の線形ニューラル ネットワーク\n",
        "\n",
        ":ラベル: `chap_regression`\n",
        "\n",
        "ニューラル ネットワークを深くすることについて心配する前に、入力が出力に直接接続される浅いニューラル ネットワークを実装すると役立ちます。これはいくつかの理由から重要であることがわかります。まず、複雑なアーキテクチャに気を取られるのではなく、出力層のパラメーター化、データの処理、損失関数の指定、モデルのトレーニングなど、ニューラル ネットワークのトレーニングの基本に集中できます。第 2 に、このクラスの浅いネットワークは、線形モデルのセットで構成されており、線形モデルやソフトマックス回帰など、統計的予測のための多くの古典的な手法が組み込まれています。これらの古典的なツールを理解することは非常に重要です。なぜなら、これらのツールは多くのコンテキストで広く使用されており、より複雑なアーキテクチャの使用を正当化するときにベースラインとして使用する必要があることが多いからです。この章では線形回帰に焦点を絞り、次の章では分類用の線形ニューラル ネットワークを開発することでモデリングのレパートリーを拡張します。\n",
        "\n",
        " :begin_tab:toc\n",
        "- [線形回帰](linear-regression.ipynb)\n",
        "- [オーデザイン](oo-design.ipynb)\n",
        "- [合成回帰データ](synthetic-regression-data.ipynb)\n",
        "- [線形回帰スクラッチ](linear-regression-scratch.ipynb)\n",
        "- [線形回帰 - 簡潔](linear-regression-concise.ipynb)\n",
        "- [一般化](generalization.ipynb)\n",
        "- [重み減少](weight-decay.ipynb):end_tab:\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
