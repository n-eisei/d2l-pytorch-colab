{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8548acf0",
      "metadata": {},
      "source": "\n# 畳み込みニューラル ネットワーク\n\n:ラベル: `chap_cnn`\n\n画像データは、モノクロでもカラーでも、ピクセルの 2 次元グリッドとして表されます。したがって、各ピクセルはそれぞれ 1 つまたは複数の数値に対応します。これまでのところ、この豊富な構造を無視し、ピクセル間の空間的関係に関係なく、画像を*平坦化する*ことで数値のベクトルとして扱いました。この非常に満足のいかないアプローチは、完全に接続された MLP を通じて結果として得られる 1 次元ベクトルを供給するために必要でした。\n\nこれらのネットワークは特徴の順序に対して不変であるため、ピクセルの空間構造に対応する順序を保存するかどうか、MLP パラメーターをフィッティングする前に設計行列の列を並べ替えるかどうかに関係なく、同様の結果を得ることができます。できれば、近くのピクセルは通常互いに関連しているという事前の知識を活用して、画像データから学習するための効率的なモデルを構築します。\n\nこの章では、まさにこの目的のために設計されたニューラル ネットワークの強力なファミリーである*畳み込みニューラル ネットワーク*(CNN) :cite: `LeCun.Jackel.Bottou.ea.1995`を紹介します。 CNN ベースのアーキテクチャは現在、コンピューター ビジョンの分野で広く普及しています。たとえば、Imagnet コレクション :cite: `Deng.Dong.Socher.ea.2009`では、大幅なパフォーマンス向上をもたらしたのは畳み込みニューラル ネットワーク、つまり Convnet の使用のみでした :cite: `Krizhevsky.Sutskever.Hinton.2012` 。\n\n口語的に呼ばれる現代の CNN は、生物学、群理論、および適度な実験的工夫からのインスピレーションに基づいて設計されています。 CNN は、正確なモデルを実現する際のサンプル効率に加えて、完全に接続されたアーキテクチャよりも必要なパラメータが少なく、畳み込みが GPU コア間で並列化されやすいため、計算効率が高い傾向があります:cite: `Chetlur.Woolley.Vandermersch.ea.2014` 。その結果、実践者は可能な限り CNN を適用することが多く、オーディオ :cite: `Abdel-Hamid.Mohamed.Jiang.ea.2014` 、テキスト :cite: など、1 次元のシーケンス構造を持つタスクでも CNN が信頼できる競争相手として台頭してきています。 `Kalchbrenner.Grefenstette.Blunsom.2014` 、および時系列分析 :cite: `LeCun.Bengio.ea.1995`では、リカレント ニューラル ネットワークが従来から使用されています。 CNN のいくつかの巧妙な適応により、CNN はグラフ構造化データ (引用: `Kipf.Welling.2016`やレコメンダー システムにも適用されています。\n\nまず、畳み込みニューラル ネットワークの動機についてさらに深く掘り下げていきます。続いて、すべての畳み込みネットワークのバックボーンを構成する基本的な操作について説明します。これらには、畳み込み層自体、パディングやストライドを含む核心的な詳細、隣接する空間領域全体で情報を集約するために使用されるプーリング層、各層での複数のチャネルの使用、現代のアーキテクチャの構造についての慎重な議論が含まれます。この章の最後に、現代の深層学習が台頭するずっと前に導入に成功した最初の畳み込みネットワークである LeNet の完全な動作例を示します。次の章では、いくつかの人気のある比較的最近の CNN アーキテクチャの完全な実装について詳しく説明します。その設計は、現代の専門家によって一般的に使用されているテクニックのほとんどを表しています。\n\n :begin_tab:toc\n- [なぜコンバージョン](why-conv.ipynb)\n- [変換層](conv-layer.ipynb)\n- [パディングとストライド](padding-and-strides.ipynb)\n- [チャンネル](channels.ipynb)\n- [プーリング](pooling.ipynb)\n- [レネット](lenet.ipynb):end_tab:\n"
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}