{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9ff3104a",
      "metadata": {},
      "source": "\n# 付録: 深層学習のための数学\n\n:label: `chap_appendix_math`\n\n **Brent Werness** ( *Amazon* )、 **Rachel Hu** ( *Amazon* )、およびこの本の著者\n\n現代の深層学習の素晴らしい点の 1 つは、その多くが、その下にある数学を完全に理解していなくても理解して使用できるという事実です。これはこの分野が成熟していることの表れです。ほとんどのソフトウェア開発者が計算可能な関数の理論について心配する必要がなくなったのと同様に、深層学習の実践者も最尤学習の理論的基礎について心配する必要はありません。\n\nしかし、私たちはまだそこまで到達していません。\n\n実際には、アーキテクチャの選択が勾配フローにどのように影響するか、または特定の損失関数を使用してトレーニングすることによって作成される暗黙の仮定を理解する必要がある場合があります。エントロピーが一体何を測定するのか、そしてそれがモデルにおける文字あたりのビット数の意味を正確に理解するのにどのように役立つのかを知る必要があるかもしれません。これらはすべて、より深い数学的理解を必要とします。\n\nこの付録は、最新の深層学習の中核理論を理解するために必要な数学的背景を提供することを目的としていますが、すべてを網羅しているわけではありません。線形代数をより深く調べることから始めます。私たちは、すべての一般的な線形代数オブジェクトと演算の幾何学的理解を深め、データに対するさまざまな変換の影響を視覚化できるようにします。重要な要素は、固有分解の基礎を開発することです。\n\n次に、微分積分の理論を発展させて、なぜ勾配が最急降下方向になるのか、そしてなぜ逆伝播がそのような形をとるのかを完全に理解できるようにします。次に、次のトピックである確率論をサポートするために必要な程度まで積分微積分について説明します。\n\n実際に遭遇する問題は不確実であることが多いため、不確実なことについて話すための言語が必要です。モデルを確率的に議論できるように、確率変数の理論と最も一般的に遭遇する分布を確認します。これは、確率的分類手法である単純ベイズ分類器の基礎を提供します。\n\n確率論と密接に関係しているのは統計の研究です。統計は短いセクションで正確に説明するには広すぎる分野ですが、すべての機械学習実践者が知っておくべき基本的な概念、特に推定量の評価と比較、仮説検定の実施、信頼区間の構築について紹介します。\n\n最後に、情報の保存と送信に関する数学的研究である情報理論の話題に移ります。これは、モデルが言説領域でどれだけの情報を保持しているかを定量的に議論するための中心的な言語を提供します。\n\nこれらを総合すると、ディープ ラーニングの深い理解に向けた道を歩み始めるために必要な数学的概念の中核を形成します。\n\n :begin_tab:toc\n- [幾何学線形代数演算](geometry-linear-algebraic-ops.ipynb)\n- [固有分解](eigendecomposition.ipynb)\n- [単一変数微積分](single-variable-calculus.ipynb)\n- [多変数微積分](multivariable-calculus.ipynb)\n- [積分計算](integral-calculus.ipynb)\n- [ランダム変数](random-variables.ipynb)\n- [最尤性](maximum-likelihood.ipynb)\n- [分布](distributions.ipynb)\n- [ナイーブベイズ](naive-bayes.ipynb)\n- [統計](statistics.ipynb)\n- [情報理論](information-theory.ipynb):end_tab:\n"
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}