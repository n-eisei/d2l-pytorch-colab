{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e0f9bff8",
      "metadata": {},
      "source": "\nこのノートブックを実行するには、次の追加ライブラリが必要です。 Colab での実行は実験的なものであることに注意してください。問題がある場合は、Github の問題を報告してください。\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c783be6",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install d2l==1.0.0-beta0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7ee05fe",
      "metadata": {},
      "source": "\n# カスタムレイヤー\n\nディープラーニングの成功の要因の 1 つは、さまざまなタスクに適したアーキテクチャを設計するために創造的な方法で構成できる幅広いレイヤーが利用できることです。たとえば、研究者は、画像、テキストの処理、連続データのループ、動的プログラミングの実行に特化したレイヤーを発明しました。遅かれ早かれ、深層学習フレームワークにまだ存在していないレイヤーに遭遇したり、発明したりすることになるでしょう。このような場合は、カスタム レイヤーを構築する必要があります。このセクションでは、その方法を説明します。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d4ab4931",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0087ce81",
      "metadata": {},
      "source": "\n## (**パラメータのないレイヤー**)\n\nまず、独自のパラメーターを持たないカスタム レイヤーを構築します。 :numref: `sec_model_construction`のモジュールの紹介を思い出していただければ、これに見覚えがあるはずです。次の`CenteredLayer`クラスは、入力から平均を単純に減算します。これを構築するには、基本層クラスから継承し、順伝播関数を実装するだけです。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ac0141bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CenteredLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, X):\n",
        "        return X - X.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "827474b3",
      "metadata": {},
      "source": "\nレイヤーにデータをフィードして、レイヤーが意図したとおりに機能することを確認してみましょう。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6b1880d1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-2., -1.,  0.,  1.,  2.])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer = CenteredLayer()\n",
        "layer(torch.tensor([1.0, 2, 3, 4, 5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d30017",
      "metadata": {},
      "source": "\nこれで、[**より複雑なモデルを構築する際に、レイヤーをコンポーネントとして組み込むことができます。** 】\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "aadbe863",
      "metadata": {},
      "outputs": [],
      "source": [
        "net = nn.Sequential(nn.LazyLinear(128), CenteredLayer())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaaed2b2",
      "metadata": {},
      "source": "\n追加の健全性チェックとして、ネットワーク経由でランダム データを送信し、平均が実際に 0 であることを確認できます。浮動小数点数を扱っているため、量子化により非常に小さな非ゼロの数値が表示される可能性があります。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a84fe9dd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0., grad_fn=<MeanBackward0>)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y = net(torch.rand(4, 8))\n",
        "Y.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0932522e",
      "metadata": {},
      "source": "\n## [**パラメータ付きレイヤー**]\n\n単純なレイヤーを定義する方法がわかったので、トレーニングを通じて調整できるパラメーターを使用してレイヤーを定義することに進みます。組み込み関数を使用してパラメータを作成し、基本的なハウスキーピング機能を提供できます。特に、アクセス、初期化、共有、保存、モデル パラメーターの読み込みを制御します。この方法には、特に、カスタム レイヤーごとにカスタム シリアル化ルーチンを作成する必要がなくなるという利点があります。\n\n次に、独自のバージョンの完全接続層を実装してみましょう。この層には 2 つのパラメーターが必要であることを思い出してください。1 つは重みを表し、もう 1 つはバイアスを表します。この実装では、ReLU アクティベーションをデフォルトとして焼き付けます。この層には 2 つの入力引数、 `in_units`と`units`が必要です。これらはそれぞれ入力と出力の数を示します。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "11e7b26d",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyLinear(nn.Module):\n",
        "    def __init__(self, in_units, units):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
        "        self.bias = nn.Parameter(torch.randn(units,))\n",
        "\n",
        "    def forward(self, X):\n",
        "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
        "        return F.relu(linear)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00ead6a6",
      "metadata": {},
      "source": "\n次に、 `MyLinear`クラスをインスタンス化し、そのモデル パラメーターにアクセスします。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5f27458f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-1.2894e+00,  6.5869e-01, -1.3933e+00],\n",
              "        [ 7.2590e-01,  7.1593e-01,  1.8115e-03],\n",
              "        [-1.5900e+00,  4.1654e-01, -1.3358e+00],\n",
              "        [ 2.2732e-02, -2.1329e+00,  1.8811e+00],\n",
              "        [-1.0993e+00,  2.9763e-01, -1.4413e+00]], requires_grad=True)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "linear = MyLinear(5, 3)\n",
        "linear.weight"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1ec0b69",
      "metadata": {},
      "source": "\n[**カスタム レイヤーを使用して順伝播計算を直接実行できます。** 】\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "556ef632",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000, 1.7772, 0.0000],\n",
              "        [0.0000, 1.0303, 0.0000]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "linear(torch.rand(2, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4219382",
      "metadata": {},
      "source": "\n(**カスタム レイヤーを使用してモデルを構築する) こともできます。**これを取得したら、組み込みの完全に接続されたレイヤーと同じように使用できます。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "067b63ba",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [0.]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
        "net(torch.rand(2, 64))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6130c834",
      "metadata": {},
      "source": "\n## まとめ\n\n基本レイヤー クラスを介してカスタム レイヤーを設計できます。これにより、ライブラリ内の既存のレイヤーとは異なる動作をする柔軟な新しいレイヤーを定義できます。カスタム レイヤーを定義すると、任意のコンテキストおよびアーキテクチャで呼び出すことができます。レイヤーにはローカル パラメーターを含めることができ、これは組み込み関数を通じて作成できます。\n\n## 演習\n1. 入力を受け取り、テンソル リダクションを計算する層を設計します。つまり、$y_k = \\sum_{i, j} W_{ijk} x_i x_j$ を返します。\n1. データのフーリエ係数の前半を返す層を設計します。\n"
    },
    {
      "cell_type": "markdown",
      "id": "93546b8d",
      "metadata": {},
      "source": "\n[ディスカッション](https://discuss.d2l.ai/t/59)\n"
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}