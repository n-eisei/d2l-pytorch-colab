{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "904d069e",
      "metadata": {},
      "source": "\n# ファイルI/O\n\nこれまで、データを処理する方法と、深層学習モデルを構築、トレーニング、テストする方法について説明しました。ただし、ある時点で、学習されたモデルに十分満足できるようになり、後でさまざまなコンテキストで使用できるように結果を保存したいと考えます (おそらく、デプロイメントで予測するためでもあります)。さらに、長いトレーニング プロセスを実行する場合、サーバーの電源コードにつまずいても数日分の計算が失われないように、中間結果 (チェックポイント) を定期的に保存することがベスト プラクティスです。したがって、個々の重みベクトルとモデル全体の両方をロードおよび保存する方法を学習するときが来ました。このセクションでは両方の問題について説明します。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8212be1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2e1a27f",
      "metadata": {},
      "source": "\n## ( **Tensor のロードと保存**)\n\n個々のテンソルについては、 `load`関数と`save`関数を直接呼び出して、それぞれ読み取りおよび書き込みを行うことができます。どちらの関数も名前を指定する必要があり、 `save`保存する変数を入力として要求します。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "935fcea6",
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.arange(4)\n",
        "torch.save(x, 'x-file')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87d37078",
      "metadata": {},
      "source": "\nこれで、保存されたファイルからデータをメモリに読み取ることができます。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3dc49fcf",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x2 = torch.load('x-file')\n",
        "x2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a07d571c",
      "metadata": {},
      "source": "\n[**テンソルのリストを保存し、それらをメモリに読み戻すことができます。** 】\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3cfb7c30",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = torch.zeros(4)\n",
        "torch.save([x, y],'x-files')\n",
        "x2, y2 = torch.load('x-files')\n",
        "(x2, y2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8d4b442",
      "metadata": {},
      "source": "\n[**文字列からテンソルにマッピングする辞書を書いたり読んだりすることもできます。** ] これは、モデル内のすべての重みを読み書きしたい場合に便利です。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "619e97a0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mydict = {'x': x, 'y': y}\n",
        "torch.save(mydict, 'mydict')\n",
        "mydict2 = torch.load('mydict')\n",
        "mydict2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb2af6bd",
      "metadata": {},
      "source": "\n## [**モデルパラメータのロードと保存**]\n\n個々の重みベクトル (または他のテンソル) を保存することは便利ですが、モデル全体を保存 (後でロード) する場合は非常に面倒になります。結局のところ、何百ものパラメータ グループが全体に散在している可能性があります。このため、深層学習フレームワークには、ネットワーク全体をロードおよび保存するための組み込み機能が提供されています。注意すべき重要な点は、これによりモデル全体ではなくモデル*パラメーターが*保存されるということです。たとえば、3 層 MLP がある場合、アーキテクチャを個別に指定する必要があります。その理由は、モデル自体に任意のコードが含まれる可能性があるため、モデルを自然にシリアル化できないためです。したがって、モデルを復元するには、コードでアーキテクチャを生成し、ディスクからパラメータをロードする必要があります。 (**おなじみの MLP から始めましょう。** )\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "903f0e92",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.LazyLinear(256)\n",
        "        self.output = nn.LazyLinear(10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.output(F.relu(self.hidden(x)))\n",
        "\n",
        "net = MLP()\n",
        "X = torch.randn(size=(2, 20))\n",
        "Y = net(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "360f2601",
      "metadata": {},
      "source": "\n次に、「mlp.params」という名前で [**モデルのパラメーターをファイルとして保存**] します。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8500ae41",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'mlp.params')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43ecba82",
      "metadata": {},
      "source": "\nモデルを復元するには、元の MLP モデルのクローンをインスタンス化します。モデルパラメータをランダムに初期化する代わりに、[**ファイルに保存されているパラメータを直接読み取ります**]。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a8035512",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (hidden): LazyLinear(in_features=0, out_features=256, bias=True)\n",
              "  (output): LazyLinear(in_features=0, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clone = MLP()\n",
        "clone.load_state_dict(torch.load('mlp.params'))\n",
        "clone.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27ab63d6",
      "metadata": {},
      "source": "\n両方のインスタンスが同じモデル パラメーターを持っているため、同じ入力`X`の計算結果は同じになるはずです。これを確認してみましょう。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c592d782",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True, True, True, True, True]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_clone = clone(X)\n",
        "Y_clone == Y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79d92728",
      "metadata": {},
      "source": "\n## まとめ\n\n`save`および`load`関数を使用して、テンソル オブジェクトのファイル I/O を実行できます。パラメータ辞書を介して、ネットワークのパラメータのセット全体を保存およびロードできます。アーキテクチャの保存は、パラメーターではなくコードで行う必要があります。\n\n## 演習\n1. トレーニング済みモデルを別のデバイスにデプロイする必要がない場合でも、モデル パラメーターを保存することの実際的な利点は何でしょうか?\n1. ネットワークの一部のみを再利用して、別のアーキテクチャのネットワークに組み込むとします。たとえば、前のネットワークの最初の 2 つのレイヤーを新しいネットワークで使用するにはどうすればよいでしょうか?\n1. ネットワーク アーキテクチャとパラメータを保存するにはどうすればよいでしょうか?アーキテクチャにどのような制限を課しますか?\n"
    },
    {
      "cell_type": "markdown",
      "id": "69e80738",
      "metadata": {},
      "source": "\n[ディスカッション](https://discuss.d2l.ai/t/61)\n"
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}