{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d497e2ac",
      "metadata": {},
      "source": "\n# サーバーとGPUの選択\n\n:label: `sec_buy_gpu`\n\nディープラーニングのトレーニングには通常、大量の計算が必要です。現在、GPU はディープラーニング用の最もコスト効率の高いハードウェア アクセラレータです。特に、GPU は CPU と比較して安価で、多くの場合桁違いに高いパフォーマンスを提供します。さらに、1 台のサーバーで複数の GPU (ハイエンド サーバーの場合は最大 8 つ) をサポートできます。より一般的な数は、熱、冷却、電力の要件がオフィス ビルでサポートできる量を超えて急速に増加するため、エンジニアリング ワークステーションでは最大 4 つの GPU です。大規模な導入の場合、クラウド コンピューティング (Amazon の[P3](https://aws.amazon.com/ec2/instance-types/p3/)および[G4](https://aws.amazon.com/blogs/aws/in-the-works-ec2-instances-g4-with-nvidia-t4-gpus/)インスタンスなど) がより実用的なソリューションです。\n\n## サーバーの選択\n\n計算の多くは GPU で行われるため、通常、多くのスレッドを備えたハイエンド CPU を購入する必要はありません。ただし、Python のグローバル インタープリタ ロック (GIL) により、GPU が 4 ～ 8 個ある状況では、CPU のシングル スレッド パフォーマンスが重要になる可能性があります。すべての条件が等しいということは、コア数が少なく、クロック周波数が高い CPU がより経済的な選択肢である可能性があることを示しています。たとえば、6 コア 4 GHz の CPU と 8 コア 3.5 GHz CPU のどちらかを選択する場合、総速度は劣りますが、前者の方がはるかに望ましいです。重要な考慮事項は、GPU が大量の電力を使用するため、大量の熱が放散されるということです。これには、非常に優れた冷却と、GPU を使用するのに十分な大きさのシャーシが必要です。可能であれば、以下のガイドラインに従ってください。\n1. **電源**。 GPU は大量の電力を使用します。デバイスあたり最大 350 W の予算を設定します (効率的なコードは大量のエネルギーを使用する可能性があるため、通常の需要ではなくグラフィック カードの*ピーク需要*を確認してください)。電力供給が需要を満たしていない場合、システムが不安定になることがあります。\n1. **シャーシのサイズ**。 GPU は大きいため、補助電源コネクタには余分なスペースが必要になることがよくあります。また、シャーシが大きいと冷却しやすくなります。\n1.  **GPUの冷却**。多数の GPU がある場合は、水冷に投資することをお勧めします。また、ファンの数が少ない場合でも、デバイス間の空気の取り込みができるほど薄いため、*リファレンス デザイン*を目指してください。マルチファン GPU を購入した場合、複数の GPU を取り付けるときに厚みがありすぎて十分な空気が得られず、サーマル スロットルが発生する可能性があります。\n1.  **PCIe スロット**。 GPU との間でデータを移動 (および GPU 間でデータを交換) するには、大量の帯域幅が必要です。 16 レーンの PCIe 3.0 スロットを推奨します。複数の GPU を取り付ける場合は、マザーボードの説明をよく読んで、複数の GPU を同時に使用する場合でも 16$\\times$ の帯域幅が利用可能であること、および追加の GPU に PCIe 2.0 ではなく PCIe 3.0 が搭載されていることを確認してください。スロット。一部のマザーボードは、複数の GPU がインストールされている場合、8$\\times$、さらには 4$\\times$ の帯域幅にダウングレードします。これは、CPU が提供する PCIe レーンの数が原因の 1 つです。\n\nつまり、ディープ ラーニング サーバーを構築するための推奨事項をいくつか示します。\n- **初心者**。消費電力の低いローエンド GPU を購入します (ディープラーニングに適した安価なゲーム用 GPU は 150 ～ 200 W を使用します)。運が良ければ、現在のコンピューターがそれをサポートします。\n-  **1 GPU** 。 4 コアのローエンド CPU で十分であり、ほとんどのマザーボードで十分です。少なくとも 32 GB の DRAM を目指し、ローカル データ アクセス用に SSD に投資します。 600Wの電源があれば十分です。ファンがたくさん付いている GPU を購入してください。\n-  **2 GPU** 。 4 ～ 6 コアのローエンド CPU で十分です。 64 GB DRAM を目指して SSD に投資します。 2 つのハイエンド GPU で約 1000 W が必要になります。メインボードに関しては、PCIe 3.0 x16 スロット*が 2 つ*あることを確認してください。可能であれば、追加の空気のために PCIe 3.0 x16 スロット間に 2 つの空きスペース (60 mm 間隔) があるメインボードを入手してください。この場合、多くのファンを備えた 2 つの GPU を購入します。\n-  **4 つの GPU** 。比較的速いシングルスレッド速度 (つまり、高いクロック周波数) を備えた CPU を購入するようにしてください。おそらく、AMD Threadripper など、より多くの PCIe レーンを備えた CPU が必要になります。 PCIe レーンを多重化するために PLX が必要になる可能性があるため、4 つの PCIe 3.0 x16 スロットを取得するには、比較的高価なメインボードが必要になる可能性があります。幅が狭く、GPU 間に空気が入るリファレンス デザインの GPU を購入してください。 1600 ～ 2000 W の電源が必要ですが、オフィスのコンセントがそれをサポートしていない可能性があります。このサーバーはおそらく*大音量で高温で*動作するでしょう。机の下に置くのは望ましくありません。 128 GB の DRAM を推奨します。ローカル ストレージ用の SSD (1 ～ 2 TB NVMe) と、データを保存するための RAID 構成のハードディスクを入手します。\n-  **8 つの GPU** 。複数の冗長電源 (たとえば、電源ごとに 1600 W の場合は 2+1) を備えた専用のマルチ GPU サーバー シャーシを購入する必要があります。これには、デュアル ソケット サーバー CPU、256 GB ECC DRAM、高速ネットワーク カード (10 GBE を推奨) が必要で、サーバーが GPU の*物理フォーム ファクター*をサポートしているかどうかを確認する必要があります。エアフローと配線の配置は、コンシューマ GPU とサーバー GPU の間で大きく異なります (例: RTX 2080 と Tesla V100)。これは、電源ケーブル用のスペースが不十分なため、または適切なワイヤリング ハーネスがないため、コンシューマ GPU をサーバーに取り付けることができない可能性があることを意味します (共著者の 1 人が痛いほど発見しました)。\n\n##  GPUの選択\n\n現在、AMD と NVIDIA が専用 GPU の 2 つの主要メーカーです。 NVIDIA はディープ ラーニングの分野に最初に参入し、CUDA を介してディープ ラーニング フレームワークのサポートを強化しています。したがって、ほとんどの購入者は NVIDIA GPU を選択します。\n\n NVIDIA は、個人ユーザー (GTX および RTX シリーズなど) と企業ユーザー (Tesla シリーズなど) をターゲットとした 2 種類の GPU を提供しています。 2 種類の GPU は同等の計算能力を提供します。ただし、エンタープライズ ユーザーの GPU は通常、(パッシブな) 強制冷却、より多くのメモリ、および ECC (エラー訂正) メモリを使用します。これらの GPU はデータセンターにより適しており、通常は消費者向け GPU の 10 倍のコストがかかります。\n\n 100 台以上のサーバーを備えた大企業の場合は、NVIDIA Tesla シリーズを検討するか、代わりにクラウドの GPU サーバーを使用する必要があります。 10 台以上のサーバーを備えた研究室または中小企業の場合、NVIDIA RTX シリーズが最もコスト効率が高いと考えられます。 4 ～ 8 個の GPU を効率的に搭載できる Supermicro または Asus シャーシを備えた事前構成済みサーバーを購入できます。\n\n GPU ベンダーは通常、2017 年にリリースされた GTX 1000 (Pascal) シリーズや 2019 年にリリースされた RTX 2000 (Turing) シリーズなど、1 ～ 2 年ごとに新世代をリリースします。各シリーズは、異なるパフォーマンス レベルを提供する複数の異なるモデルを提供しています。 GPU のパフォーマンスは主に次の 3 つのパラメータの組み合わせです。\n1. **計算能力**。通常、私たちは 32 ビット浮動小数点の計算能力を求めます。 16 ビット浮動小数点トレーニング (FP16) も主流になりつつあります。予測のみに興味がある場合は、8 ビット整数を使用することもできます。最新世代の Turing GPU は 4 ビット アクセラレーションを提供します。残念ながら、現時点では、低精度のネットワークをトレーニングするアルゴリズムはまだ普及していません。\n1. **メモリサイズ**。モデルが大きくなったり、トレーニング中に使用されるバッチが大きくなったりすると、より多くの GPU メモリが必要になります。 HBM2 (高帯域幅メモリ) と GDDR6 (グラフィックス DDR) メモリを確認します。 HBM2 は高速ですが、はるかに高価です。\n1. **メモリ帯域幅**。十分なメモリ帯域幅がある場合にのみ、コンピューティング能力を最大限に活用できます。 GDDR6 を使用している場合は、幅の広いメモリ バスを探してください。\n\nほとんどのユーザーにとって、計算能力を確認するだけで十分です。多くの GPU がさまざまなタイプのアクセラレーションを提供していることに注意してください。たとえば、NVIDIA の TensorCore は演算子のサブセットを 5$\\times$ 高速化します。ライブラリがこれをサポートしていることを確認してください。 GPU メモリは 4 GB 以上である必要があります (8 GB のほうがはるかに優れています)。 GUI の表示にも GPU を使用しないようにしてください (代わりに内蔵グラフィックスを使用してください)。これを回避できない場合は、安全のために 2 GB の RAM を追加してください。\n\n :numref: `fig_flopsvsprice` 、さまざまな GTX 900、GTX 1000、RTX 2000 シリーズ モデルの 32 ビット浮動小数点の計算能力と価格を比較します。価格はウィキペディアに記載されている推奨価格です。 \n\n![](http://d2l.ai/_images/flopsvsprice.svg) :ラベル: `fig_flopsvsprice`\n\nさまざまなことがわかります。\n1. 各シリーズ内では、価格と性能はほぼ比例します。 Titan モデルは、大容量の GPU メモリを利用できるため、大幅な割増料金がかかります。ただし、980 Ti と 1080 Ti を比較するとわかるように、新しいモデルの方がコスト効率が優れています。 RTX 2000シリーズの価格はあまり改善されないようです。ただし、これは、はるかに優れた低精度パフォーマンス (FP16、INT8、および INT4) を提供するという事実によるものです。\n1.  GTX 1000 シリーズのパフォーマンス対コスト比は、900 シリーズの約 2 倍です。\n1.  RTX 2000 シリーズの場合、パフォーマンス (GFLOPS 単位) は価格の*アフィン*関数です。 \n\n![](http://d2l.ai/_images/wattvsprice.svg) :ラベル: `fig_wattvsprice`\n\n :numref: `fig_wattvsprice` 、エネルギー消費が計算量に応じてほぼ線形に増加する様子を示しています。第二に、後の世代の方が効率的です。これはRTX 2000シリーズに対応するグラフと矛盾しているように見えます。ただし、これは TensorCore が不釣り合いに多くのエネルギーを消費する結果です。\n\n## まとめ\n- サーバーを構築するときは、電源、PCIe バス レーン、CPU シングル スレッド速度、冷却に注意してください。\n- 可能であれば、最新世代の GPU を購入する必要があります。\n- 大規模な展開にはクラウドを使用します。\n- 高密度サーバーはすべての GPU と互換性があるわけではありません。購入する前に機械および冷却の仕様を確認してください。\n- 高効率を得るにはFP16以下の精度を使用してください。\n\n[ディスカッション](https://discuss.d2l.ai/t/425)\n"
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}