{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bd08e17e",
      "metadata": {},
      "source": "\nこのノートブックを実行するには、次の追加ライブラリが必要です。 Colab での実行は実験的なものであることに注意してください。問題がある場合は、Github の問題を報告してください。\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c05ad2c",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install d2l==1.0.0-beta0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f73f17b",
      "metadata": {},
      "source": "\n# エンコーダ/デコーダのアーキテクチャ\n\n:label: `sec_encoder-decoder`\n\n機械翻訳 (:numref: `sec_machine_translation` ) のような一般的な seq2seq 問題では、入力と出力は整列されていないさまざまな長さになります。この種のデータを処理する標準的なアプローチは、可変長シーケンスを入力として受け取る*エンコーダー*と、条件付き言語として機能する*デコーダー*という 2 つの主要コンポーネントで構成される*エンコーダー デコーダー*アーキテクチャ (:numref: `fig_encoder_decoder` ) を設計することです。モデルでは、エンコードされた入力とターゲット シーケンスの左方向のコンテキストを取得し、ターゲット シーケンス内の後続のトークンを予測します。 \n\n![](../img/encoder-decoder.svg):label: `fig_encoder_decoder`\n\n例として、英語からフランス語への機械翻訳を見てみましょう。英語の入力シーケンス「They」、「are」、「watching」、「.」が与えられると、このエンコーダー/デコーダー アーキテクチャは、まず可変長入力を状態にエンコードし、次にその状態をデコードして、翻訳されたシーケンス、トークンを生成します。出力としてトークンごと: \"Ils\"、\"regardent\"、\".\"。エンコーダ/デコーダ アーキテクチャは後続のセクションでさまざまな seq2seq モデルの基礎を形成するため、このセクションではこのアーキテクチャを後で実装されるインターフェイスに変換します。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9667c33d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0a1e05c",
      "metadata": {},
      "source": "\n## (**エンコーダ**)\n\nエンコーダー インターフェイスでは、エンコーダーが可変長シーケンスを入力`X`として受け取ることを指定するだけです。実装は、この基本`Encoder`クラスを継承する任意のモデルによって提供されます。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "60f1cb0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):  #@save\n",
        "    \"\"\"The base encoder interface for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    # Later there can be additional arguments (e.g., length excluding padding)\n",
        "    def forward(self, X, *args):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "321655fd",
      "metadata": {},
      "source": "\n## [**デコーダ**]\n\n次のデコーダ インターフェイスでは、エンコーダ出力 ( `enc_all_outputs` ) をエンコードされた状態に変換するための`init_state`メソッドを追加します。このステップでは、 :numref: `sec_machine_translation`で説明した入力の有効な長さなど、追加の入力が必要になる場合があることに注意してください。可変長シーケンストークンをトークンごとに生成するには、デコーダが入力 (たとえば、前のタイムステップで生成されたトークン) とエンコードされた状態を現在のタイムステップでの出力トークンにマッピングするたびに行います。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b41f6031",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):  #@save\n",
        "    \"\"\"The base decoder interface for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    # Later there can be additional arguments (e.g., length excluding padding)\n",
        "    def init_state(self, enc_all_outputs, *args):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ba19a75",
      "metadata": {},
      "source": "\n## [**エンコーダとデコーダを組み合わせる**]\n\n順方向伝播では、エンコーダの出力はエンコードされた状態を生成するために使用され、この状態はデコーダによってその入力の 1 つとしてさらに使用されます。\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4c7c6c48",
      "metadata": {},
      "outputs": [],
      "source": [
        "class EncoderDecoder(d2l.Classifier):  #@save\n",
        "    \"\"\"The base class for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, enc_X, dec_X, *args):\n",
        "        enc_all_outputs = self.encoder(enc_X, *args)\n",
        "        dec_state = self.decoder.init_state(enc_all_outputs, *args)\n",
        "        # Return decoder output only\n",
        "        return self.decoder(dec_X, dec_state)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5d61029",
      "metadata": {},
      "source": "\n次のセクションでは、このエンコーダ/デコーダ アーキテクチャに基づいて RNN を適用して seq2seq モデルを設計する方法を見ていきます。\n\n## まとめ\n\nエンコーダ/デコーダ アーキテクチャは、両方とも可変長シーケンスで構成される入力と出力を処理できるため、機械翻訳などの seq2seq 問題に適しています。エンコーダーは可変長シーケンスを入力として受け取り、それを固定形状の状態に変換します。デコーダは、固定形状の符号化状態を可変長シーケンスにマッピングします。\n\n## 演習\n1. ニューラル ネットワークを使用してエンコーダ/デコーダ アーキテクチャを実装すると仮定します。エンコーダーとデコーダーは同じタイプのニューラル ネットワークである必要がありますか?\n1. 機械翻訳以外に、エンコーダ/デコーダ アーキテクチャを適用できる別のアプリケーションを思いつきますか?\n"
    },
    {
      "cell_type": "markdown",
      "id": "2b95aa40",
      "metadata": {},
      "source": "\n[ディスカッション](https://discuss.d2l.ai/t/1061)\n"
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}