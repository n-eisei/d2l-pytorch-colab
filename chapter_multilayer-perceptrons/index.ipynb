{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "004967b7",
      "metadata": {},
      "source": "\n# 多層パーセプトロン\n\n:label: `chap_perceptrons`\n\nこの章では、初めての真に*深い*ネットワークを紹介します。最も単純な深層ネットワークは*多層パーセプトロン*と呼ばれ、複数のニューロン層で構成されており、それぞれが下の層 (入力を受け取る層) と上の層 (順番に影響を与える) の層に完全に接続されています。自動微分により深層学習アルゴリズムの実装が大幅に簡素化されますが、深層ネットワークでこれらの勾配がどのように計算されるかについて詳しく説明します。次に、ディープ ネットワークのトレーニングを成功させるための鍵となる数値安定性とパラメーターの初期化に関する問題について説明する準備をします。このような大容量モデルをトレーニングすると、過剰学習のリスクが生じます。したがって、ディープネットワークの正則化と一般化を再検討します。全体を通して、概念だけでなく、ディープ ネットワークの使用方法についてもしっかりと理解できるようにすることを目的としています。この章の最後では、これまで紹介したことを実際のケース、つまり住宅価格の予測に適用します。モデルの計算パフォーマンス、スケーラビリティ、効率に関する事項は後続の章に移します。\n\n :begin_tab:toc\n-  [mlp](mlp.ipynb)\n-  [mlp 実装](mlp-implementation.ipynb)\n- [バックプロップ](backprop.ipynb)\n- [数値安定性と初期化](numerical-stability-and-init.ipynb)\n- [一般化の深い](generalization-deep.ipynb)\n- [脱落](dropout.ipynb)\n- [カグルハウス価格](kaggle-house-price.ipynb):end_tab:\n"
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}