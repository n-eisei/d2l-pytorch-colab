{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b8558a-1e36-4b59-82d6-2ab1ce133375",
   "metadata": {},
   "source": [
    "\n",
    "# 序章\n",
    "\n",
    ":label: `chap_introduction`\n",
    "\n",
    "最近まで、日常的に使用するほぼすべてのコンピューター プログラムは、どのように動作するかを正確に指定する一連の厳格なルールとしてコード化されていました。電子商取引プラットフォームを管理するアプリケーションを作成したいとします。数時間ホワイトボードの周りに集まって問題を熟考した後、実用的なソリューションの大まかな方針に落ち着くかもしれません。たとえば、(i) ユーザーは、Web ブラウザーまたはモバイル アプリケーションで実行されるインターフェイスを通じてアプリケーションと対話します。 (ii) 当社のアプリケーションは、商用グレードのデータベース エンジンと対話して、各ユーザーの状態を追跡し、取引履歴の記録を維持します。 (iii) アプリケーションの中心となる*ビジネス ロジック*(*頭脳*とも言える) は、考えられるすべての状況を、プログラムが取るべき対応するアクションにマッピングする一連のルールを詳しく説明します。\n",
    "\n",
    "アプリケーションの頭脳を構築するには、プログラムが処理する必要があるすべての一般的なイベントを列挙します。たとえば、顧客がクリックして商品をショッピング カートに追加するたびに、プログラムはショッピング カート データベース テーブルにエントリを追加し、そのユーザーの ID を要求された製品の ID に関連付けます。その後、考えられるすべてのコーナーケースを段階的に検討し、ルールの適切性をテストし、必要な修正を加えることもあります。ユーザーが空のカートで購入を開始するとどうなりますか?最初から完全に正しく理解できる開発者はほとんどいませんが (問題を解決するためにいくつかのテスト実行が必要になる場合があります)、ほとんどの場合、私たちはそのようなプログラムを作成し、実際の顧客に会う*前に*自信を持って起動することができます。多くの場合、新しい状況で機能する製品やシステムを駆動する自動化システムを手動で設計する私たちの能力は、驚くべき認知的偉業です。そして、$100%$ の確率で機能するソリューションを考案できれば、通常は機械学習について心配する必要はありません。\n",
    "\n",
    "成長を続ける機械学習科学者のコミュニティにとって幸いなことに、私たちが自動化したいタスクの多くは、人間の創意工夫にそう簡単に屈するものではありません。最も賢明な頭脳を持つ人々がホワイトボードの周りに群がっているところを想像してみてください。しかし今回は、次の問題のいずれかに取り組んでいます。\n",
    "- 地理情報、衛星画像、過去の天気のトレーリング ウィンドウを考慮して、明日の天気を予測するプログラムを作成します。\n",
    "- 自由形式のテキストで表現された事実上の質問を受け取り、それに正しく答えるプログラムを作成します。\n",
    "- 与えられた画像から、そこに描かれているすべての人物を識別し、それぞれの周囲に輪郭を描くプログラムを作成してください。\n",
    "- ユーザーが楽しみそうな製品を、ブラウジングの自然な過程で遭遇する可能性は低い製品をユーザーに提示するプログラムを作成します。\n",
    "\n",
    "これらの問題については、エリート プログラマーであっても、解決策をゼロからコード化するのは困難です。理由はさまざまです。私たちが探しているプログラムは、時間の経過とともに変化するパターンに従っていることもあるため、固定された正解はありません。このような場合、成功するソリューションは、変化する世界に適切に適応する必要があります。場合によっては、関係 (ピクセルと抽象カテゴリ間の関係など) が複雑すぎて、数千または数百万の計算が必要となり、未知の原理に従うこともあります。画像認識の場合、私たちの潜在意識の認知プロセスは難なくタスクを実行しますが、タスクを実行するために必要な正確な手順は私たちの意識的な理解を超えています。\n",
    "\n",
    "*機械学習は*、経験から学習できるアルゴリズムの研究です。機械学習アルゴリズムが、通常は観測データや環境との相互作用の形で経験を蓄積するにつれて、そのパフォーマンスが向上します。これを、当社の決定論的な e コマース プラットフォームと比較してください。このプラットフォームは、どれだけ経験が積まれても、開発者自身が学習してソフトウェアを更新する時期が来たと判断するまで、同じビジネス ロジックに従います。この本では、コンピューター ビジョン、自然言語処理、ヘルスケア、ゲノミクスなどのさまざまな分野でイノベーションを推進する強力な技術セットである*ディープ ラーニング*に特に焦点を当てて、機械学習の基礎を説明します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba29a346-786f-40ac-9367-5471df0e199d",
   "metadata": {},
   "source": [
    "\n",
    "## やる気を起こさせる例\n",
    "\n",
    "この本の著者も、多くの労働者と同様に、執筆を始める前にカフェインを摂取する必要がありました。私たちは車に飛び乗って運転を始めました。アレックスは iPhone を使って「Hey Siri」と呼びかけ、電話の音声認識システムを起動させました。それからムーは「ブルーボトルコーヒーショップへの道順」を命令した。電話にはすぐに彼の命令の文字起こしが表示された。また、私たちが道順を尋ねていることを認識し、その要求を満たすためにマップ アプリケーション (アプリ) を起動しました。マップ アプリを起動すると、多くのルートが識別されました。各ルートの横に、携帯電話には予測される通過時間が表示されました。私たちはこのストーリーを教育上の便宜のためにでっちあげましたが、ほんの数秒の間に、私たちのスマートフォンとの日常的なやりとりがいくつかの機械学習モデルに関与する可能性があることを示しています。\n",
    "\n",
    " 「Alexa」、「OK Google」、「Hey Siri」などの*ウェイクワード*に応答するプログラムを作成するだけだと想像してみてください。 :numref: `fig_wake_word`に示すように、コンピューターとコード エディターだけを使用して、部屋で自分でコードを作成してみてください。第一原理からそのようなプログラムをどのように作成しますか?考えてみてください...問題は難しいです。マイクは毎秒約 44000 個のサンプルを収集します。各サンプルは音波の振幅の測定値です。生の音声のスニペットから、そのスニペットにウェイクワードが含まれているかどうかの信頼できる予測 ${\\text{yes}, \\text{no}}$ に確実にマッピングできるルールは何でしょうか?行き詰まった場合でも、心配しないでください。私たちもそのようなプログラムを最初から書く方法を知りません。これが、私たちが機械学習を使用する理由です。\n",
    "\n",
    "![](../img/wake-word.svg) :label: `fig_wake_word`\n",
    "\n",
    "ここにトリックがあります。多くの場合、入力から出力へのマッピング方法をコンピューターに明示的に伝える方法が分からない場合でも、私たちは自分自身で認知的偉業を実行することができます。言い換えれば、「Alexa」という単語を認識するようにコンピューターをプログラムする方法を知らなくても、あなた自身がそれを認識することができるのです。この機能を利用すると、音声スニペットと関連するラベルの例を含む巨大な*データセット*を収集し、どのスニペットにウェイク ワードが含まれているかを示すことができます。機械学習への主流のアプローチでは、ウェイクワードを*明示的に*認識するシステムを設計しようとはしません。代わりに、動作が多数の*パラメータ*によって決定される柔軟なプログラムを定義します。次に、データセットを使用して、可能な限り最良のパラメータ値、つまり、選択したパフォーマンス測定に関してプログラムのパフォーマンスを向上させるパラメータ値を決定します。\n",
    "\n",
    "パラメータは、プログラムの動作を操作するために回すことができるノブと考えることができます。パラメータを固定したプログラムを*モデル*と呼びます。パラメーターを操作するだけで作成できるすべての個別のプログラム (入出力マッピング) のセットは、モデルの*ファミリー*と呼ばれます。データセットを使用してパラメータを選択するメタプログラムは、*学習アルゴリズム*と呼ばれます。\n",
    "\n",
    "学習アルゴリズムを実行する前に、問題を正確に定義し、入力と出力の正確な性質を特定し、適切なモデル ファミリを選択する必要があります。この場合、モデルは*入力*として音声のスニペットを受け取り、*出力*として ${\\text{yes}、\\text{no}}$ の中から選択を生成します。すべてが計画通りに進んだ場合、通常、スニペットにウェイク ワードが含まれているかどうかについてのモデルの推測は正確になります。\n",
    "\n",
    "適切なモデルファミリーを選択した場合、モデルが「Alexa」という単語を聞くたびに「はい」と発声するようなノブの設定が 1 つ存在するはずです。ウェイク ワードの正確な選択は任意であるため、ノブの別の設定を介して、「アプリコット」という単語を聞いたときにのみ「はい」と発声できる、十分に豊富なモデル ファミリが必要になるでしょう。 「Alexa」認識と「Apricot」認識は直感的に同様のタスクに見えるため、同じモデルファミリーが適していると予想されます。ただし、根本的に異なる入力または出力を処理したい場合、たとえば画像からキャプションへ、または英語の文章から中国語の文章へ​​マッピングしたい場合は、まったく異なるモデルのファミリーが必要になる可能性があります。\n",
    "\n",
    "ご想像のとおり、すべてのノブをランダムに設定した場合、モデルが「Alexa」、「Apricot」、またはその他の英語の単語を認識する可能性は低くなります。機械学習における*学習は*、モデルから望ましい動作を強制するノブの適切な設定を発見するプロセスです。言い換えれば、データを使用してモデルを*トレーニングします*。 :numref: `fig_ml_loop`に示すように、トレーニング プロセスは通常次のようになります。\n",
    "1. 何も役立つことのないランダムに初期化されたモデルから始めます。\n",
    "1. データの一部を取得します (例: 音声スニペットと、対応する ${\\text{yes}、\\text{no}}$ ラベル)。\n",
    "1. ノブを微調整して、これらの例での評価に従ってモデルのパフォーマンスを向上させます。\n",
    "1. モデルが素晴らしいものになるまで、ステップ 2 と 3 を繰り返します。\n",
    "\n",
    "![](../img/ml-loop.svg) :label: `fig_ml_loop`\n",
    "\n",
    "要約すると、ウェイク ワード認識装置をコード化するのではなく、大規模なラベル付きデータセットが提示された場合にウェイク ワードの認識を*学習*できるプログラムをコード化します。データセットを提示することでプログラムの動作を決定するこの行為を、 *data を使用したプログラミングと*考えることができます。つまり、機械学習システムに猫と犬の多くの例を提供することで、猫検出器を「プログラム」することができます。このようにして、検出器は最終的に、猫の場合は非常に大きな正の数を、犬の場合は非常に大きな負の数を、不明な場合はゼロに近い値を出力することを学習します。これは機械学習ができることのほんの表面をなぞっただけです。ディープ ラーニングは、後ほど詳しく説明しますが、機械学習の問題を解決するための多くの一般的な方法のうちの 1 つにすぎません。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f71461-72fd-4544-acc0-833874caaaea",
   "metadata": {},
   "source": [
    "\n",
    "## 主要コンポーネント\n",
    "\n",
    "ウェイク ワードの例では、オーディオ スニペットとバイナリ ラベルで構成されるデータセットについて説明し、スニペットから分類へのマッピングを近似するためにモデルをトレーニングする方法を手作業で説明しました。ラベルが既知である例で構成されるデータセットを与えられた場合に、既知の入力に基づいて指定された未知のラベルを予測しようとするこの種の問題は、*教師あり学習*と呼ばれます。これは、さまざまな種類の機械学習の問題のうちの 1 つにすぎません。他の種類を検討する前に、どのような種類の機械学習の問題に取り組む場合でも、私たちをフォローするいくつかのコアコンポーネントについてさらに光を当てたいと思います。\n",
    "1. 私たちが学ぶことができる*データ*。\n",
    "1. データを変換する方法の*モデル*。\n",
    "1. モデルがどの程度うまく機能している (または悪くなっているか) を定量化する*目的関数*。\n",
    "1. モデルのパラメーターを調整して目的関数を最適化する*アルゴリズム*。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61231520-198f-40e5-a927-86ad93c29a49",
   "metadata": {},
   "source": [
    "\n",
    "### データ\n",
    "\n",
    "言うまでもないことかもしれませんが、データがなければデータサイエンスは行えません。データとは正確には何な*のかを*深く考えると何百ページも無駄になる可能性がありますが、今のところは、関心のあるデータセットの主要なプロパティに焦点を当てます。一般に、私たちは例のコレクションに関心を持っています。データを効果的に操作するには、通常、適切な数値表現を考え出す必要があります。各*サンプル*(または*データ ポイント*、*データ インスタンス*、*サンプル*) は通常、*特徴*(*共変量*または*入力*と呼ばれることもあります) と呼ばれる属性のセットで構成されており、これに基づいてモデルは予測を行う必要があります。教師あり学習問題では、モデルの入力の一部ではない*ラベル*(または*ターゲット*) と呼ばれる特別な属性の値を予測することが目標です。\n",
    "\n",
    "画像データを扱う場合、各例は個々の写真 (特徴) とその写真が属するカテゴリを示す番号 (ラベル) で構成されます。写真は、各ピクセル位置における赤、緑、青の光の明るさを表す 3 つの数値グリッドとして数値的に表されます。たとえば、$200\\times 200$ のカラー写真は、$200\\times200\\times3=120000$ の数値で構成されます。\n",
    "\n",
    "あるいは、電子医療記録データを利用して、特定の患者が今後 30 日間生存する可能性を予測するタスクに取り組むことも考えられます。ここで、私たちの特徴は、年齢、バイタルサイン、併存疾患、現在の投薬、最近の処置など、すぐに利用できる属性と頻繁に記録される測定値のコレクションで構成されている可能性があります。トレーニングに使用できるラベルは、履歴データ内の各患者が 30 日以内に生存したかどうかを示すバイナリ値になります。\n",
    "\n",
    "このような場合、すべての例が同じ数の数値特徴によって特徴付けられるとき、入力は固定長ベクトルであると言い、ベクトルの (一定の) 長さをデータの*次元*と呼びます。ご想像のとおり、固定長入力は便利であり、複雑な心配が 1 つ減ります。ただし、すべてのデータを*固定長*ベクトルとして簡単に表現できるわけではありません。顕微鏡画像が標準装備から提供されることを期待するかもしれませんが、インターネットからマイニングされた画像がすべて同じ解像度や形状で表示されることを期待することはできません。画像の場合、すべてを標準サイズにトリミングすることを検討するかもしれませんが、その戦略では限界があります。切り取られた部分の情報が失われる危険があります。さらに、テキスト データは固定長表現に対してさらに頑固に抵抗します。 Amazon、IMDb、TripAdvisor などの電子商取引サイトに残された顧客レビューを検討してください。 「臭い！」という短いものもあります。他の人はページをとりとめなく書きます。従来の方法に対するディープ ラーニングの大きな利点の 1 つは、最新のモデルが*可変長*データを比較的スムーズに処理できることです。\n",
    "\n",
    "一般に、データが多ければ多いほど、仕事は簡単になります。より多くのデータがあれば、より強力なモデルをトレーニングできるようになり、事前に考えられた仮定にそれほど依存する必要がなくなりました。 （比較的）小規模なデータからビッグデータへの体制の変化が、現代のディープラーニングの成功に大きく貢献しています。要点を強調しておきますが、深層学習の最もエキサイティングなモデルの多くは、大規模なデータセットがなければ機能しません。他のいくつかは小規模データ領域で動作しますが、従来のアプローチと比べて優れたものではありません。\n",
    "\n",
    "最後に、大量のデータを保有し、それを賢く処理するだけでは十分ではありません。*正しい*データが必要です。データに間違いがたくさんある場合、または選択した特徴が対象となる目標量を予測できない場合、学習は失敗します。この状況は、「*ゴミが入ったらゴミが出てくる」*という決まり文句によってよく表現されています。さらに、予測パフォーマンスの低下だけが潜在的な結果ではありません。予測ポリシング、履歴書審査、融資に使用されるリスク モデルなど、機械学習の機密性の高いアプリケーションでは、ガベージ データの影響に特に注意する必要があります。一般的な障害モードの 1 つは、一部の人々のグループがトレーニング データに含まれていないデータセットで発生します。これまで黒い肌を見たことがなかった野生動物に皮膚がん認識システムを適用することを想像してみてください。データが一部のグループを過小評価しているだけでなく、社会的な偏見を反映している場合にも、失敗が発生する可能性があります。たとえば、履歴書を審査するために使用される予測モデルをトレーニングするために過去の採用決定が使用されている場合、機械学習モデルが誤って過去の不公平を捉えて自動化してしまう可能性があります。これらはすべて、データ サイエンティストが積極的に共謀することなく、あるいは認識することなく発生する可能性があることに注意してください。\n",
    "\n",
    "### モデル\n",
    "\n",
    "ほとんどの機械学習には、ある意味でデータの変換が含まれます。写真を取り込んで笑顔度を予測するシステムを構築したいと思うかもしれません。あるいは、一連のセンサー読み取り値を取り込み、その読み取り値がどの程度正常であるか異常であるかを予測したい場合もあります。*モデル*とは、あるタイプのデータを取り込み、おそらく異なるタイプの予測を吐き出すための計算機構を示します。特に、データから推定できる統計モデルに興味があります。単純なモデルは適切な単純な問題に完全に対処できますが、本書で焦点を当てる問題は古典的な手法の限界を超えています。ディープ ラーニングは、主に焦点を当てている一連の強力なモデルによって従来のアプローチと区別されます。これらのモデルは、上から下に連鎖した多くの連続したデータ変換で構成されているため、*ディープ ラーニング*という名前が付けられています。ディープモデルについて説明する途中で、より伝統的な方法についても説明します。\n",
    "\n",
    "### 目的関数\n",
    "\n",
    "先ほど、機械学習を経験からの学習として紹介しました。ここで*学習する*とは、時間の経過とともに何らかのタスクを改善することを意味します。しかし、何が改善であると誰が言えるでしょうか?私たちがモデルの更新を提案できるかもしれないと想像するかもしれませんが、提案された更新が改善なのか低下なのかについて意見が異なる人もいるかもしれません。\n",
    "\n",
    "学習機械の正式な数学システムを開発するには、モデルがどの程度良い (または悪い) かを正式に測定する必要があります。機械学習、およびより一般的な最適化では、これらを*目的関数*と呼びます。慣例により、通常、目的関数は低いほど良いように定義されます。これは単なる慣例です。高いほど優れている関数を選択し、符号を反転することで、定性的には同じであるが低いほど優れている新しい関数に変えることができます。低いほど優れているため、これらの関数は*損失関数*と呼ばれることもあります。\n",
    "\n",
    "数値を予測しようとする場合、最も一般的な損失関数は*二乗誤差*、つまり予測とグランド トゥルース ターゲットの差の二乗です。分類の最も一般的な目的は、エラー率、つまり、予測がグランドトゥルースと一致しない例の割合を最小限に抑えることです。一部の目的 (二乗誤差など) は最適化が簡単ですが、他の目的 (誤差率など) は、非微分可能性やその他の複雑さのため、直接最適化するのが困難です。このような場合、*代理目標を*最適化するのが一般的です。\n",
    "\n",
    "最適化中、損失をモデルのパラメーターの関数として考え、トレーニング データセットを定数として扱います。トレーニングのために収集されたいくつかのサンプルで構成されるセットで発生する損失を最小限に抑えることで、モデルのパラメーターの最適な値を学習します。ただし、トレーニング データで適切な結果が得られたとしても、目に見えないデータでも適切な結果が得られるとは限りません。したがって、通常は、利用可能なデータを 2 つのパーティションに分割します。1 つはモデル パラメーターの学習用の*トレーニング データセット*(または*トレーニング セット*) です。および評価のために保持される*テスト データセット*(または*テスト セット*)。通常、1 日の終わりに、モデルが両方のパーティションでどのように実行されるかを報告します。トレーニングのパフォーマンスは、実際の最終試験の準備に使用される模擬試験で学生が達成したスコアに似ていると考えることができます。たとえ良い結果が得られたとしても、それが最終試験での成功を保証するものではありません。学習の過程で、学生は練習問題を暗記し始め、トピックをマスターしたように見えても、実際の最終試験でこれまで見たことのない問題に直面するとたじろぐ場合があります。モデルがトレーニング セットでは良好に機能するが、目に見えないデータに対して一般化できない場合、モデルがトレーニング データに対して*過剰適合して*いると言います。\n",
    "\n",
    "### 最適化アルゴリズム\n",
    "\n",
    "データ ソースと表現、モデル、および明確に定義された目的関数を取得したら、損失関数を最小化するための最良のパラメーターを検索できるアルゴリズムが必要になります。深層学習の一般的な最適化アルゴリズムは、*勾配降下法*と呼ばれるアプローチに基づいています。つまり、このメソッドは各ステップで、パラメーターごとに、そのパラメーターをほんの少しだけ摂動させた場合にトレーニング セットの損失がどの方向に移動するかを確認します。次に、損失を下げる方向にパラメータを更新します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c445d848-b838-41cb-8416-6ce7a28353c8",
   "metadata": {},
   "source": [
    "\n",
    "## 機械学習の問題の種類\n",
    "\n",
    "私たちの動機付けの例におけるウェイクワードの問題は、機械学習が取り組むことができる多くの問題のうちの 1 つにすぎません。読者の意欲をさらに高め、本書全体を通して続く共通言語を提供するために、ここでは機械学習の問題定式化の状況の広範な概要を提供します。\n",
    "\n",
    "### 教師あり学習\n",
    "\n",
    "教師あり学習では、特徴とラベルの両方を含むデータセットが与えられ、入力特徴が与えられた場合にラベルを予測するモデルを作成するタスクが説明されます。各特徴とラベルのペアはサンプルと呼ばれます。場合によっては、コンテキストが明確な場合、対応するラベルが不明な場合でも、入力のコレクションを参照するために例という*用語*を使用することがあります。パラメーターを選択するために、私たち (スーパーバイザー) がラベル付きの例で構成されるデータセットをモデルに提供するため、スーパーバイザーが機能します。確率論的に言えば、通常、入力特徴が与えられたラベルの条件付き確率を推定することに関心があります。教師あり学習は、機械学習内のいくつかのパラダイムのうちの 1 つにすぎませんが、業界における機械学習の成功したアプリケーションの大部分を占めています。その理由の 1 つは、多くの重要なタスクは、特定の利用可能なデータ セットを基に未知の何かの確率を推定することであると明確に説明できるためです。\n",
    "- コンピューター断層撮影画像を基に、癌かそうでないかを予測します。\n",
    "- 英語の文章に対して、フランス語での正しい翻訳を予測します。\n",
    "- 今月の財務報告データに基づいて、来月の株価を予測します。\n",
    "\n",
    "すべての教師あり学習の問題は「入力特徴が与えられたラベルを予測する」という単純な説明で捉えられますが、教師あり学習はさまざまな形式をとり、入力の種類、サイズ、量に応じて大量のモデリングの決定が必要になる場合があります。そして出力。たとえば、任意の長さのシーケンスを処理する場合と、固定長のベクトル表現を処理する場合には、異なるモデルを使用します。この本では、これらの問題の多くを詳しく見ていきます。\n",
    "\n",
    "非公式には、学習プロセスは次のようになります。まず、特徴がわかっているサンプルの大きなコレクションを取得し、その中からランダムなサブセットを選択し、それぞれのグラウンド トゥルース ラベルを取得します。これらのラベルは、すでに収集されている利用可能なデータである場合もあります (たとえば、患者は翌年に死亡しましたか?) 場合もありますが、データにラベルを付けるために人間のアノテーターを雇う必要がある場合もあります (たとえば、画像をカテゴリに割り当てる)。これらの入力と対応するラベルを合わせてトレーニング セットを構成します。トレーニング データセットを教師あり学習アルゴリズムに入力します。この関数はデータセットを入力として受け取り、別の関数である学習済みモデルを出力します。最後に、その出力を対応するラベルの予測として使用して、これまで目に見えなかった入力を学習済みモデルにフィードすることができます。完全なプロセスは :numref: `fig_supervised_learning`に描かれています。\n",
    "\n",
    "![](../img/supervised-learning.svg) :label: `fig_supervised_learning`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeedc2c1-13a6-447e-9629-6dcab53663fe",
   "metadata": {},
   "source": [
    "\n",
    "#### 回帰\n",
    "\n",
    "おそらく、頭を悩ませる最も単純な教師あり学習タスクは*回帰*です。たとえば、住宅販売のデータベースから収集された一連のデータを考えてみましょう。各行が異なる家に対応し、各列が家の面積、寝室の数、バスルームの数、徒歩の分数などの関連する属性に対応するテーブルを作成するとします。 ）街の中心部へ。このデータセットでは、各例は特定の住宅となり、対応する特徴ベクトルはテーブル内の 1 行になります。あなたがニューヨークまたはサンフランシスコに住んでいて、Amazon、Google、Microsoft、または Facebook の CEO ではない場合、あなたの家の特徴ベクトル (面積、寝室の数、バスルームの数、徒歩距離) $[600, 1, 1, 60]$ のようになります。ただし、ピッツバーグに住んでいる場合は、$[3000, 4, 3, 10]$ のように見えるかもしれません。このような固定長の特徴ベクトルは、ほとんどの古典的な機械学習アルゴリズムに不可欠です。\n",
    "\n",
    "問題を回帰にするのは、実際にはターゲットの形式です。あなたが新しい家を探しているとします。上記のようないくつかの特徴を考慮して、住宅の公正市場価格を推定するとよいでしょう。ここでのデータは過去の住宅リストで構成され、ラベルは観察された販売価格である可能性があります。ラベルが（一定の間隔内であっても）任意の数値を取る場合、これを*回帰*問題と呼びます。目標は、予測が実際のラベル値に非常に近いモデルを作成することです。\n",
    "\n",
    "実際の問題の多くは回帰問題として簡単に説明できます。ユーザーが映画に割り当てる評価を予測することは回帰問題と考えることができ、2009 年にこの偉業を達成する優れたアルゴリズムを設計していれば、 [100 万ドルの Netflix 賞を](https://en.wikipedia.org/wiki/Netflix_Prize)獲得できたかもしれません。患者の入院期間の予測も回帰問題です。経験則としては、*いくらくらいでしょうか?*それとも*何人ですか？*問題は回帰を示唆するはずです。例:\n",
    "- この手術には何時間かかりますか?\n",
    "- この町には今後 6 時間でどれくらいの雨が降りますか?\n",
    "\n",
    "これまで機械学習に取り組んだことがなくても、非公式に回帰問題に取り組んだことがあるはずです。たとえば、排水管を修理し、請負業者が 3 時間かけて下水管から汚物を除去したと想像してください。それから彼はあなたに 350 ドルの請求書を送りました。ここで、あなたの友人が同じ請負業者に 2 時間雇い、250 ドルの請求書を受け取ったと想像してください。次に、誰かが次回の汚れ除去の請求書にどのくらいの金額を期待しているかを尋ねたら、労働時間が長くなると費用がかかるなど、いくつかの合理的な仮定を立てるかもしれません。また、基本料金があり、請負業者は時間ごとに料金を請求すると仮定することもできます。これらの仮定が当てはまる場合、これらの 2 つのデータ例を考慮すると、請負業者の価格体系、つまり 1 時間あたり 100 ドルに加えて、自宅に来てもらうために 50 ドルがかかることがすでに特定できます。そこまで理解していれば、線形回帰の背後にある高度な概念をすでに理解していることになります。\n",
    "\n",
    "この場合、請負業者の価格に正確に一致するパラメータを作成できました。場合によっては、これが不可能な場合もあります。たとえば、差異の一部が 2 つの特徴以外のいくつかの要因による場合などです。このような場合、予測と観測値の間の距離を最小化するモデルを学習しようとします。ほとんどの章では、二乗誤差損失関数を最小化することに焦点を当てます。後で説明するように、この損失は、データがガウス ノイズによって破損したという仮定に対応します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1705e98-7249-4902-ad7c-180909e3ca35",
   "metadata": {},
   "source": [
    "\n",
    "#### 分類\n",
    "\n",
    "回帰モデルは*いくつあるのかに対処するのに最適ですが、*多くの問題は、このテンプレートにうまく適応できません。たとえば、モバイル アプリ用の小切手スキャン機能を開発したい銀行について考えてみましょう。理想的には、顧客が小切手の写真を撮るだけで、アプリが画像からテキストを自動的に認識します。各手書き文字に対応する画像パッチをセグメント化する能力があると仮定すると、残りの主なタスクは、既知のセットの中のどの文字が各画像パッチに描かれているかを判断することになります。これらの種類は*どれですか？*問題は*分類*と呼ばれ、回帰に使用されるものとは異なるツールのセットが必要ですが、多くの手法は引き継がれます。\n",
    "\n",
    "*分類*では、モデルが画像内のピクセル値などの特徴を調べ、その例がいくつかの離散的なオプションのセットの中でどの*カテゴリ*(*クラス*と呼ばれることもあります) に属するかを予測する必要があります。手書きの数字の場合、0 ～ 9 の数字に対応する 10 個のクラスがある可能性があります。分類の最も単純な形式は、クラスが 2 つしかない場合であり、これを*2 値分類*と呼ぶ問題です。たとえば、データセットは動物の画像で構成され、ラベルはクラス $\\mathrm{{cat, Dog}}$ になる可能性があります。回帰では、数値を出力する回帰子を探しますが、分類では、予測されたクラス割り当てを出力する分類器を探します。\n",
    "\n",
    "理由については、本がより専門的になると説明しますが、「猫」または「犬」などの厳密なカテゴリ割り当てのみを出力できるモデルを最適化するのは難しい場合があります。このような場合、通常は代わりに確率の言語でモデルを表現する方がはるかに簡単です。例の特徴を考慮して、モデルは考えられる各クラスに確率を割り当てます。クラスが $\\mathrm{{cat, Dog}}$ である動物分類の例に戻ると、分類器は画像を見て、その画像が猫である確率を 0.9 として出力する可能性があります。この数値は、分類器が画像に猫が描かれていることを 90% 確信していると解釈できます。予測されたクラスの確率の大きさは、不確実性の 1 つの概念を表します。不確実性の唯一の概念ではありません。他の概念については、より高度な章で説明します。\n",
    "\n",
    "考えられるクラスが 3 つ以上ある場合、その問題を*マルチクラス分類*と呼びます。一般的な例には、手書き文字認識 $\\mathrm{{0, 1, 2, ... 9, a, b, c, ...}}$ などがあります。私たちは二乗誤差損失関数を最小化することによって回帰問題を攻撃しましたが、分類問題の一般的な損失関数は*クロスエントロピー*と呼ばれます。その名前は、後続の章の情報理論の入門を通じて謎を解くことができます。\n",
    "\n",
    "最も可能性の高いクラスが、必ずしも決定に使用するクラスであるとは限らないことに注意してください。 :numref: `fig_death_cap`に示すように、裏庭で美しいキノコを見つけたとします。\n",
    "\n",
    "![](../img/death-cap.jpg) :幅: `200px` :ラベル: `fig_death_cap`\n",
    "\n",
    "ここで、分類器を構築し、写真に基づいてキノコが有毒かどうかを予測するようにトレーニングしたと仮定します。毒物検出分類器が、:numref: `fig_death_cap`にデス キャップが含まれる確率が 0.2 であると出力するとします。言い換えれば、分類子は、キノコがデスキャップではないことを 80% 確信しています。それでも、それを食べるのは愚かでなければなりません。それは、おいしいディナーの確かな利益は、それによって死亡する20%のリスクを負う価値がないからです。言い換えれば、不確実なリスクの影響が利益をはるかに上回っているということです。したがって、キノコを食べるかどうかを決定するには、起こり得る結果と、それぞれに関連する利益または害の両方に応じて、各行動に関連する予想される不利益を計算する必要があります。この場合、キノコを食べることによって生じる不利益は $0.2 \\times \\infty + 0.8 \\times 0 = \\infty$ ですが、キノコを廃棄した場合の損失は $0.2 \\times 0 + 0.8 \\times 1 = 0.8$ となります。私たちの警戒は正当でした。菌学者なら誰でも言うように、:numref: `fig_death_cap`のキノコは実際にはデスキャップです。\n",
    "\n",
    "分類は、単なるバイナリ分類またはマルチクラス分類よりもはるかに複雑になる場合があります。たとえば、階層構造のクラスに対応する分類のバリエーションがいくつかあります。このような場合、すべてのエラーが等しいわけではありません。どうしてもエラーが発生する場合は、離れたクラスではなく関連するクラスに誤分類することを選択する可能性があります。通常、これは*階層分類*と呼ばれます。インスピレーションとして、動物を階層構造に組織した[リンネ](https://en.wikipedia.org/wiki/Carl_Linnaeus)を思い浮かべるかもしれません。\n",
    "\n",
    "動物の分類の場合、プードルをシュナウザーと間違えることはそれほど悪いことではないかもしれませんが、私たちのモデルがプードルと恐竜を間違えた場合、大きなペナルティを支払うことになります。どの階層が関連するかは、モデルの使用方法によって異なる場合があります。たとえば、ガラガラヘビとガーターヘビは系統樹上では近いかもしれませんが、ガラガラヘビとガーターヘビを間違えると致命的になる可能性があります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41594010-4d7b-4df9-91fa-55aea1b99e5a",
   "metadata": {},
   "source": [
    "\n",
    "#### タグ付け\n",
    "\n",
    "一部の分類問題は、バイナリまたはマルチクラスの分類設定にうまく適合します。たとえば、猫と犬を区別するために通常のバイナリ分類器をトレーニングできます。コンピューター ビジョンの現在の状況を考慮すると、既製のツールを使用してこれを簡単に行うことができます。それにもかかわらず、モデルがどれほど正確であっても、分類子が 4 匹の動物が登場する人気のあるドイツのおとぎ話である*ブレーメンの音楽隊*の画像に遭遇すると、問題が発生する可能性があります (:numref: `fig_stackedanimals` )。\n",
    "\n",
    "![](../img/stackedanimals.png) :幅: `300px` :ラベル: `fig_stackedanimals`\n",
    "\n",
    "ご覧のとおり、この写真には猫、鶏、犬、ロバが描かれており、背景にはいくつかの木があります。このような画像に遭遇すると予想される場合、マルチクラス分類は適切な問題定式化ではない可能性があります。代わりに、画像が猫、犬、ロバ*、*雄鶏を描いていると言うオプションをモデルに与えたくなるかもしれません。\n",
    "\n",
    "相互に排他的でないクラスを予測する方法を学習する問題は、*マルチラベル分類*と呼ばれます。自動タグ付けの問題は、通常、複数ラベル分類の問題として説明するのが最も適切です。 「機械学習」、「テクノロジー」、「ガジェット」、「プログラミング言語」、「Linux」、「クラウド コンピューティング」、「AWS」など、人々が技術ブログの投稿に付けるタグを考えてみましょう。一般的な記事には 5 ～ 10 個のタグが適用される場合があります。通常、タグは何らかの相関構造を示します。 「クラウド コンピューティング」に関する投稿では「AWS」が言及される可能性が高く、「機械学習」に関する投稿では「GPU」について言及される可能性が高くなります。\n",
    "\n",
    "場合によっては、このようなタグ付けの問題は、膨大なラベル セットを必要とすることがあります。米国立医学図書館では、PubMed でインデックス付けされる各論文を、約 28,000 個のタグのコレクションである Medical Subject Headings (MeSH) オントロジーから抽出された一連のタグに関連付ける専門のアノテーターを多数雇用しています。論文に正しくタグを付けることは、研究者が文献の徹底的なレビューを行うことができるため重要です。これは時間のかかるプロセスであり、アノテーターがアーカイブしてからタグ付けするまでには通常 1 年の遅れがあります。機械学習は、各記事が手動で適切にレビューされるまで、暫定的なタグを提供できます。実際、数年間にわたり、BioASQ 組織はこの課題に関する[コンテストを主催して](http://bioasq.org/)きました。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab6a72a-4d6f-48e1-9eeb-10c354187fd4",
   "metadata": {},
   "source": [
    "\n",
    "#### 検索\n",
    "\n",
    "情報検索の分野では、項目のセットに対してランキングを課すことがよくあります。ウェブ検索を例に考えてみましょう。目標は、特定のページがクエリに関連している*かどうかを*判断することではなく、関連する一連の結果の中でどれを特定のユーザーに最も目立つように表示するかを決定することです。考えられる解決策の 1 つは、まずセット内のすべての要素にスコアを割り当ててから、最も評価の高い要素を取得することです。 Google 検索エンジンの背後にある元の秘密のソースである[PageRank は](https://en.wikipedia.org/wiki/PageRank)、そのようなスコアリング システムの初期の例でした。奇妙なことに、PageRank によって提供されるスコアは実際のクエリに依存しませんでした。代わりに、単純な関連性フィルターを使用して関連する候補のセットを特定し、PageRank を使用してより権威のあるページに優先順位を付けました。現在、検索エンジンは機械学習と動作モデルを使用して、クエリ依存の関連性スコアを取得しています。このテーマに特化した学術会議が多数あります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a4cb48-be9d-4c55-a549-613ca0c3eac8",
   "metadata": {},
   "source": [
    "\n",
    "#### 推薦システム\n",
    "\n",
    ":label: `subsec_recommender_systems`\n",
    "\n",
    "レコメンダー システムは、検索とランキングに関連するもう 1 つの問題設定です。関連する項目のセットをユーザーに表示することが目的であるという点では、問題は似ています。主な違いは、レコメンダー システムのコンテキストにおける特定のユーザーへの*パーソナライゼーション*に重点が置かれていることです。たとえば、映画のおすすめの場合、SF ファン向けの結果ページとピーター セラーズ コメディの愛好家向けの結果ページは大きく異なる可能性があります。同様の問題は、小売製品、音楽、ニュースの推奨など、他の推奨設定でも発生します。\n",
    "\n",
    "場合によっては、顧客が明示的なフィードバックを提供して、特定の製品がどれほど気に入ったかを伝えます (Amazon、IMDb、Goodreads での製品の評価やレビューなど)。他の場合には、プレイリストのタイトルをスキップするなど、暗黙のフィードバックを提供します。これは、不満を示している可能性があるか、単にその曲が文脈上不適切であることを示している可能性があります。最も単純な定式化では、これらのシステムは、期待される星評価や特定のユーザーが特定のアイテムを購入する確率など、何らかのスコアを推定するようにトレーニングされます。\n",
    "\n",
    "このようなモデルがあれば、任意のユーザーについて、最大のスコアを持つオブジェクトのセットを取得でき、それをユーザーに推奨できます。実稼働システムはかなり高度であり、スコアを計算する際に詳細なユーザー アクティビティとアイテムの特性が考慮されます。 :numref: `fig_deeplearning_amazon`アストンの好みを把握するように調整されたパーソナライゼーション アルゴリズムに基づいて、Amazon が推奨する深層学習の書籍を表示します。 \n",
    "\n",
    "![](../img/deeplearning-amazon.jpg) :label: `fig_deeplearning_amazon`\n",
    "\n",
    "莫大な経済的価値があるにもかかわらず、予測モデルに基づいて単純に構築されたレコメンデーション システムには、いくつかの重大な概念的欠陥があります。まず、私たちは*検閲されたフィードバック*のみを観察します。つまり、ユーザーは自分が強く感じている映画を優先的に評価します。たとえば、5 段階評価では、アイテムが 1 つ星と 5 つ星の評価を多く受けているのに、3 つ星評価が著しく少ないことに気づくかもしれません。さらに、現在の購入習慣は、現在導入されている推奨アルゴリズムの結果であることがよくありますが、学習アルゴリズムでは常にこの詳細が考慮されるわけではありません。したがって、レコメンダー システムがアイテムを優先的にプッシュし、そのアイテムが (購入数が多いため) より優れていると判断され、さらに頻繁に推奨されるというフィードバック ループが形成される可能性があります。検閲、インセンティブ、フィードバック ループにどのように対処するかに関するこれらの問題の多くは、重要な未解決の研究課題です。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7c121-4552-4ccc-919d-2e8ebea2757a",
   "metadata": {},
   "source": [
    "\n",
    "#### シーケンス学習\n",
    "\n",
    "これまで、一定数の入力があり、一定数の出力が生成される問題を見てきました。たとえば、平方フィート、寝室の数、バスルームの数、ダウンタウンまでの移動時間などの一定の特徴を考慮して住宅価格を予測することを検討しました。また、（固定次元の）画像から、それが固定数のクラスのそれぞれに属する予測確率へのマッピングや、ユーザー ID と製品 ID のみに基づいて購入に関連する星の評価を予測することについても説明しました。このような場合、モデルがトレーニングされると、各テスト例がモデルに入力された後、すぐに忘れられてしまいます。連続した観測は独立しているため、このコンテキストを保持する必要はないと仮定しました。\n",
    "\n",
    "しかし、ビデオのスニペットはどのように扱えばよいのでしょうか?この場合、各スニペットは異なる数のフレームで構成されている可能性があります。また、前後のフレームを考慮すると、各フレームで何が起こっているかについての推測がより強力になる可能性があります。言語についても同様です。ディープ ラーニングの問題の 1 つは、機械翻訳です。これは、あるソース言語で文を取り込み、別の言語での翻訳を予測するタスクです。\n",
    "\n",
    "こうした問題は医療でも起こります。集中治療室の患者を監視し、今後 24 時間以内に死亡するリスクがあるしきい値を超えるたびにアラートを発するモデルが必要になる場合があります。ここでは、患者の病歴についてわかっていることをすべて捨てて、最新の測定値のみに基づいて予測を行うことはありません。\n",
    "\n",
    "これらの問題は、機械学習の最も魅力的な応用例の 1 つであり、*シーケンス学習*の例です。モデルが入力シーケンスを取り込むか、出力シーケンスを出力する (またはその両方) ことが必要です。具体的には、*シーケンス間学習では、*入力と出力の両方が可変長シーケンスで構成される問題を考慮します。例としては、機械翻訳や音声からテキストへの文字起こしなどが挙げられます。すべてのタイプのシーケンス変換を考慮することは不可能ですが、次の特殊なケースについては言及する価値があります。\n",
    "\n",
    "**タグ付けと解析**。これには、テキスト シーケンスに属性の注釈を付けることが含まれます。ここで、入力と出力は*整列して*います。つまり、入力と出力は同じ番号であり、対応する順序で発生します。たとえば、*品詞 (PoS) タグ付け*では、文内のすべての単語に対応する品詞、つまり「名詞」または「直接目的語」の注釈を付けます。あるいは、連続する単語のどのグループが、*人*、*場所*、*組織*などの名前付きエンティティを参照しているのかを知りたい場合もあります。以下の漫画のように単純な例では、文内のすべての単語について、それが名前付きエンティティ (「Ent」としてタグ付けされている) の一部であるかどうかを示したいだけかもしれません。\n",
    "\n",
    "**自動音声認識**。音声認識では、入力シーケンスは話者の音声録音 (:numref: `fig_speech` ) であり、出力は話者の発言のトランスクリプトになります。課題は、テキストよりもはるかに多くのオーディオ フレーム (サウンドは通常 8kHz または 16kHz でサンプリングされます) が存在することです。つまり、数千のサンプルが 1 つの話し言葉に対応する可能性があるため、オーディオとテキストの間に 1:1 の対応関係はありません。これらはシーケンス間の学習問題であり、出力は入力よりもはるかに短くなります。人間はたとえ低品質の音声であっても音声を認識することに非常に優れていますが、コンピューターにこの偉業を実行させるのは非常に困難です。\n",
    "\n",
    "![](../img/speech.png) :幅: `700px` :ラベル: `fig_speech`\n",
    "\n",
    "**テキスト読み上げ**。これは自動音声認識の逆です。ここでは、入力はテキスト、出力は音声ファイルです。この場合、出力は入力よりもはるかに長くなります。\n",
    "\n",
    "**機械翻訳**。対応する入力と出力が同じ順序で発生する音声認識の場合とは異なり、機械翻訳では、整列されていないデータが新たな課題を引き起こします。ここで、入力シーケンスと出力シーケンスは異なる長さを持つことができ、それぞれのシーケンスの対​​応する領域は異なる順序で表示される可能性があります。動詞を文の最後に置くドイツ人特有の傾向を示す次の例を考えてみましょう。\n",
    "\n",
    "関連する多くの問題が他の学習タスクでも発生します。たとえば、ユーザーが Web ページを読む順序を決定することは、2 次元レイアウト分析の問題です。対話の問題にはあらゆる種類のさらなる複雑さが伴い、次に何を言うかを決定するには、現実世界の知識と、長い時間的距離にわたる会話の以前の状態を考慮する必要があります。これらは活発な研究分野です。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be01f822-a368-4ba4-9597-904ede5ccae7",
   "metadata": {},
   "source": [
    "\n",
    "### 教師なし学習と自己教師あり学習\n",
    "\n",
    "前の例は教師あり学習に焦点を当てており、特徴と対応するラベル値の両方を含む巨大なデータセットをモデルに供給しました。教師あり学習者は、非常に専門的な仕事と非常に独裁的な上司を持っていると考えることができます。上司は肩越しに立ち上がり、あなたが状況から行動へのマッピングを学ぶまで、あらゆる状況で何をすべきかを正確に指示します。そんな上司の下で働くのはかなりダサく思えます。一方、そのような上司を喜ばせるのは非常に簡単です。できるだけ早くパターンを認識し、彼らの行動を真似するだけです。\n",
    "\n",
    "逆の状況を考えると、あなたに何をしてほしいのか全く分からない上司の下で働くのはイライラするかもしれません。ただし、データサイエンティストになることを計画している場合は、データサイエンティストに慣れたほうがよいでしょう。上司はあなたに巨大なデータのダンプを渡し、*それを使ってデータ サイエンスを行うように指示するかもしれません。*これは曖昧に聞こえるためです。私たちはこのクラスの問題を*教師なし学習と*呼び、質問できる質問の種類と数は私たちの創造性によってのみ制限されます。教師なし学習手法については後の章で説明します。ここでは、皆さんの食欲を刺激するために、皆さんが抱くであろう次の質問についていくつか説明します。\n",
    "- データを正確に要約した少数のプロトタイプを見つけることができるでしょうか?一連の写真が与えられた場合、それらを風景写真、犬、赤ちゃん、猫、山頂の写真にグループ化できますか?同様に、ユーザーの閲覧アクティビティのコレクションが与えられた場合、それらを同様の行動を持つユーザーにグループ化できるでしょうか?この問題は通常、*クラスタリング*として知られています。\n",
    "- データの関連するプロパティを正確に捕捉する少数のパラメーターを見つけることはできるでしょうか?ボールの軌道は、ボールの速度、直径、質量によってよく表されます。仕立て屋は、衣服をフィッティングする目的で、人体の形状をかなり正確に記述する少数のパラメータを開発しました。これらの問題は、*部分空間推定*と呼ばれます。依存関係が線形である場合、それは*主成分分析*と呼ばれます。\n",
    "- シンボリックなプロパティがよく一致するような、(任意に構造化された) オブジェクトの表現がユークリッド空間に存在するでしょうか?これは、「ローマ」 $-$ 「イタリア」 $+$ 「フランス」 $=$ 「パリ」など、エンティティとその関係を記述するために使用できます。\n",
    "- 私たちが観察するデータの多くの根本原因についての説明はありますか?たとえば、住宅価格、公害、犯罪、場所、教育、給与に関する人口統計データがある場合、単に経験的データに基づいてそれらがどのように関連しているかを発見できるでしょうか?*因果*関係と*確率的グラフィカル モデル*に関連する分野は、このような問題に取り組みます。\n",
    "- 教師なし学習におけるもう 1 つの重要かつ刺激的な最近の発展は、深層生成モデルの出現です。これらのモデルは、明示的または*暗黙的に*データの密度を推定します。トレーニングが完了すると、生成モデルを使用して、可能性の高さに応じて例をスコアリングしたり、学習した分布から合成例をサンプリングしたりできます。生成モデリングにおける初期の深層学習のブレークスルーは*、変分オートエンコーダー*の発明によってもたらされました :cite: `Kingma.Welling.2014,rezende2014stochastic` 、そして*生成敵対的ネットワーク*の開発とともに継続されました :cite: `Goodfellow.Pouget-Abadie.Mirza.ea.2014` 。最近の進歩には、流れの正規化 :cite: `dinh2014nice,dinh2017density`および拡散モデル :cite: `sohl2015deep,song2019generative,ho2020denoising,song2021score`が含まれます。\n",
    "\n",
    "教師なし学習の主な発展は、ラベルなしデータのある側面を利用して監督を提供する手法である*自己教師あり学習*の台頭です。テキストの場合、ラベル付けの手間をかけずに、大きなコーパス内の周囲の単語 (コンテキスト) を使用してランダムにマスクされた単語を予測することで、「空白を埋める」ようにモデルをトレーニングできます :cite: `Devlin.Chang.Lee.ea.2018` !画像の場合、同じ画像の 2 つの切り取られた領域間の相対位置を伝えるモデルをトレーニングすることもできます (引用: `Doersch.Gupta.Efros.2015` )。画像の残りの部分に基づいて画像の遮蔽された部分を予測したり、 2 つのサンプルが、同じ基礎となる画像の摂動されたバージョンであるかどうかを予測します。自己教師ありモデルは多くの場合、表現を学習し、その後、対象となる下流のタスクで結果のモデルを微調整することで活用されます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966c920f-48e1-45f0-b658-e4f8ea9fe940",
   "metadata": {},
   "source": [
    "\n",
    "### 環境との対話\n",
    "\n",
    "これまでのところ、データが実際にどこから来るのか、または機械学習モデルが出力を生成するときに実際に何が起こるのかについては説明していません。それは、教師あり学習と教師なし学習では、これらの問題に非常に洗練された方法で対処できないためです。どちらの場合でも、事前に大量のデータを取得し、環境と再度対話することなくパターン認識マシンを稼働させます。すべての学習はアルゴリズムが環境から切断された後に行われるため、これは*オフライン学習*と呼ばれることもあります。たとえば、教師あり学習では、 :numref: `fig_data_collection`に示されている単純な対話パターンが想定されます。 \n",
    "\n",
    "![](../img/data-collection.svg) :label: `fig_data_collection`\n",
    "\n",
    "このシンプルなオフライン学習には魅力があります。利点は、動的な環境との相互作用から生じる複雑さを心配することなく、パターン認識を単独で心配できることです。しかし、この問題の定式化には限界があります。アシモフのロボット小説を読んで育った人なら、予測を行うだけでなく、世界で行動を起こすこともできる人工知能エージェントを想像するかもしれません。私たちは、単なる予測モデルではなく、インテリジェント*エージェント*について考えたいと考えています。これは、単に予測を行うのではなく、*アクション*の選択について考える必要があることを意味します。単なる予測とは異なり、行動は実際に環境に影響を与えます。インテリジェント エージェントをトレーニングしたい場合は、そのアクションがエージェントの将来の観察にどのような影響を与えるかを考慮する必要があります。\n",
    "\n",
    "環境との相互作用を考慮すると、一連の新しいモデリングの問題が生まれます。以下はほんの数例です。\n",
    "- 環境は私たちが以前に行ったことを覚えていますか?\n",
    "- 環境は私たちを助けたいと思っていますか? たとえば、ユーザーが音声認識装置にテキストを読み込むなどです。\n",
    "- 環境は私たちに勝つことを望んでいますか? たとえば、スパマーがスパムフィルターを回避するために電子メールを変更するなどですか?\n",
    "- 環境には変化する力学があるのでしょうか?たとえば、将来のデータは常に過去に似ているのでしょうか、それともパターンは時間の経過とともに自然にまたは自動ツールに応じて変化するのでしょうか?\n",
    "\n",
    "これらの疑問は、トレーニング データとテスト データが異なる*分布*シフトの問題を引き起こします。私たちのほとんどは、宿題がティーチングアシスタントによって作成されたのに、講師によって書かれた試験を受けるときにこの問題を経験したことがあります。次に、エージェントが環境と対話する学習問題を提起するための豊富なフレームワークである強化学習について簡単に説明します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335bc65a-90bf-4f25-93ce-6f2e42b99778",
   "metadata": {},
   "source": [
    "\n",
    "### 強化学習\n",
    "\n",
    "機械学習を使用して環境と対話し、アクションを実行するエージェントを開発することに興味がある場合は、おそらく*強化学習*に焦点を当てることになるでしょう。これには、ロボット工学、対話システム、さらにはビデオ ゲーム用の人工知能 (AI) の開発への応用が含まれる可能性があります。強化*学習*の問題に深層学習を適用する深層強化学習の人気が急上昇しています。視覚入力のみを使用して Atari ゲームで人間を破った画期的なディープ Q ネットワーク :cite: `mnih2015human`と、ボードゲームの囲碁で世界チャンピオンの座を奪った AlphaGo プログラム :cite: `Silver.Huang.Maddison.ea.2016`は 2 つです。顕著な例。\n",
    "\n",
    "強化学習は、エージェントが一連の時間ステップにわたって環境と対話するという問題についての非常に一般的な記述を与えます。各タイム ステップで、エージェントは環境から何らかの*観測*を受け取り、その後何らかのメカニズム (*アクチュエーター*と呼ばれることもあります) を介して環境に送り返される*アクション*を選択する必要があります。最後に、エージェントは環境から報酬を受け取ります。このプロセスは、 :numref: `fig_rl-environment`に示されています。エージェントはその後の観察を受け取り、その後のアクションを選択する、というようになります。強化学習エージェントの動作は、*ポリシー*によって制御されます。つまり、*ポリシーは*環境の観察を行動にマッピングする機能にすぎません。強化学習の目標は、優れたポリシーを生み出すことです。\n",
    "\n",
    "![](../img/rl-environment.svg) :label: `fig_rl-environment`\n",
    "\n",
    "強化学習フレームワークの一般性を誇張することはできません。たとえば、教師あり学習問題を強化学習問題としてキャストできます。分類の問題があったとします。各クラスに対応する 1 つのアクションを持つ強化学習エージェントを作成できます。その後、元の教師あり学習問題からの損失関数とまったく同じ報酬を与える環境を作成できました。\n",
    "\n",
    "そうは言っても、強化学習は教師あり学習では解決できない多くの問題にも対処できます。たとえば、教師あり学習では、トレーニング入力が正しいラベルに関連付けられることを常に期待します。しかし、強化学習では、観測ごとに環境が最適なアクションを教えてくれるとは想定しません。一般的に、私たちは何らかの報酬を受け取るだけです。さらに、環境はどの行動が報酬につながったのかさえ教えてくれないかもしれません。\n",
    "\n",
    "チェスのゲームを考えてみましょう。唯一の本当の報酬信号は、ゲームの終了時に、勝って例えば 1 の報酬を獲得するか、負けて例えば -1 の報酬を受け取るときに発生します。したがって、強化学習者は、*単位の割り当ての*問題、つまり、結果に対してどの行動を認めるべきか、または責任を負わせるかを決定する必要があります。 10 月 11 日に昇進する従業員にも同じことが当てはまります。その昇進には、おそらく前年に適切に選択された多数の行動が反映されています。将来さらに昇進を目指すには、その過程でどのような行動が昇進につながったのかを把握する必要があります。\n",
    "\n",
    "強化学習者は、部分的な可観測性の問題にも対処しなければならない場合があります。つまり、現在の観察では現在の状態についてすべてがわかるわけではないということです。たとえば、掃除ロボットが家の中にたくさんある同じクローゼットの 1 つに閉じ込められてしまったとしましょう。ロボットの正確な位置を推測するには、クローゼットに入る前にロボットが以前に観察したことを考慮する必要があるかもしれません。\n",
    "\n",
    "最後に、任意の時点で、強化学習者は 1 つの優れたポリシーを知っている可能性がありますが、エージェントが試したことのないより優れたポリシーが他にたくさんある可能性があります。強化学習者は、（現時点で）既知の最良の戦略をポリシーとして*活用する*か、戦略の空間を*探索する*かを常に選択する必要があり、知識と引き換えに短期的な報酬を放棄する可能性があります。\n",
    "\n",
    "一般的な強化学習の問題は、非常に一般的な設定です。アクションはその後の観察に影響を与えます。報酬は、選択したアクションに応じてのみ観察されます。環境は完全にまたは部分的に観察されます。このすべての複雑さを一度に説明するには、研究者に多くのことを要求しすぎる可能性があります。さらに、すべての実際的な問題がこのような複雑さを示すわけではありません。その結果、研究者は強化学習問題の特殊なケースを多数研究してきました。\n",
    "\n",
    "環境が完全に観察された場合、強化学習問題を*マルコフ決定プロセス*と呼びます。状態が前のアクションに依存しない場合、その問題を*コンテキストバンディット問題*と呼びます。状態がなく、最初は報酬が不明な利用可能なアクションのセットだけがある場合、この問題は古典的な*多腕バンディット問題*です。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660a353b-7ebe-4bc7-a623-f45061452ea4",
   "metadata": {},
   "source": [
    "\n",
    "## ルーツ\n",
    "\n",
    "機械学習で対処できる問題の小さなサブセットを確認しました。機械学習のさまざまな問題に対して、ディープ ラーニングはそれらを解決するための強力なツールを提供します。多くの深層学習手法は最近発明されたものですが、データからの学習の背後にある中心となる考え方は何世紀にもわたって研究されてきました。実際、人間はデータを分析し、将来の結果を予測したいという欲求を長年持ち続けており、自然科学の多くはこれに根ざしています。たとえば、ベルヌーイ分布は[Jacob Bernoulli (1655--1705)](https://en.wikipedia.org/wiki/Jacob_Bernoulli)にちなんで命名され、ガウス分布は[Carl Friedrich Gauss (1777--1855)](https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss)によって発見されました。たとえば、ガウスは最小平均二乗アルゴリズムを発明しました。このアルゴリズムは、保険の計算から医療診断に至るまで、現在でも無数の問題に使用されています。これらのツールは、自然科学における実験的アプローチを生み出しました。たとえば、抵抗器の電流と電圧に関するオームの法則は、線形モデルによって完全に記述されます。\n",
    "\n",
    "中世であっても、数学者は推定に関する鋭い直観を持っていました。たとえば、 [ヤコブ ケーベル (1460--1533)](https://www.maa.org/press/periodicals/convergence/mathematical-treasures-jacob-kobels-geometry)の幾何学の本には、16 人の成人男性の足の長さを平均して母集団の平均足の長さを推定する方法が示されています (:numref: `fig_koebel` )。\n",
    "\n",
    "![](../img/koebel.jpg) :幅: `500px` :ラベル: `fig_koebel`\n",
    "\n",
    "集団が教会から出てくると、成人男性16人が一列に並んで足のサイズを測るよう求められた。これらの測定値の合計を 16 で割って、現在の 1 フィートに相当する推定値を取得しました。この「アルゴリズム」は後に、足の変形に対処するために改良されました。最も短い足と最も長い足を持つ2人の男性が退場となり、残りの平均点のみが得られました。これはトリミング平均推定値の最も初期の例の 1 つです。\n",
    "\n",
    "統計は、データの収集と利用が可能になることで本格的に始まりました。その先駆者の一人である[ロナルド フィッシャー (1890--1962) は](https://en.wikipedia.org/wiki/Ronald_Fisher)、その理論と遺伝学への応用に大きく貢献しました。彼のアルゴリズム (線形判別分析など) と公式 (フィッシャー情報行列など) の多くは、現代の統計学の基礎において依然として重要な位置を占めています。彼のデータリソースさえも永続的な影響を及ぼしました。フィッシャーが 1936 年にリリースした Iris データセットは、機械学習アルゴリズムをデモンストレーションするために今でも時々使用されています。フィッシャーは優生学の支持者でもありました。このことは、道徳的に疑わしいデータ サイエンスの使用には、産業や自然科学における生産的な使用と同じくらい長く永続的な歴史があることを思い出させるはずです。\n",
    "\n",
    "機械学習に対する 2 番目の影響は[、クロード シャノン (1916 ～ 2001)](https://en.wikipedia.org/wiki/Claude_Shannon)による情報理論と、[アラン チューリング (1912 ～ 1954)](https://en.wikipedia.org/wiki/Alan_Turing)による計算理論から来ました。チューリングは「機械は考えることができるのか?」という疑問を投げかけました。彼の有名な論文*Computing Machinery and Intelligence* :cite: `Turing.1950` . 彼がチューリング テストとして説明したものでは、人間の評価者が機械からの応答と人間ベースの応答を区別するのが難しい場合、機械は*知的で*あると見なすことができます。テキストのやりとりについて。\n",
    "\n",
    "神経科学と心理学にも別の影響が見られます。結局のところ、人間は明らかに知的な行動を示します。多くの学者は、この能力を説明し、リバースエンジニアリングできるかどうかを尋ねてきました。生物学にヒントを得た最古のアルゴリズムの 1 つは[、ドナルド ヘブ (1904 ～ 1985 年)](https://en.wikipedia.org/wiki/Donald_O._Hebb)によって定式化されました。彼の画期的な著書*「行動の組織化」* :cite: `Hebb.Hebb.1949`では、ニューロンは正の強化によって学習すると主張しました。これはヘビアン学習規則として知られるようになりました。これらのアイデアは、ローゼンブラットのパーセプトロン学習アルゴリズムなどの後の作品に影響を与え、今日の深層学習を支える多くの確率的勾配降下法アルゴリズムの基礎を築きました。ニューラル ネットワークのパラメーターの適切な設定を取得するために、望ましい動作を強化し、望ましくない動作を減少させます。\n",
    "\n",
    "生物学的なインスピレーションが*ニューラル ネットワークの*名前の由来です。 1 世紀以上にわたって (1873 年のアレクサンダー ベインと 1890 年のジェームス シェリントンのモデルにまで遡る)、研究者たちは相互作用するニューロンのネットワークに似た計算回路を組み立てようと試みてきました。時間が経つにつれて、生物学の解釈は文字通りではなくなりましたが、その名前は定着しました。その中心には、今日のほとんどのネットワークに見られるいくつかの重要な原則があります。\n",
    "- 線形処理ユニットと非線形処理ユニットを交互に配置したもので、 *「レイヤー」*と呼ばれることがよくあります。\n",
    "- ネットワーク全体のパラメータを一度に調整するためのチェーン ルール (*バックプロパゲーション*とも呼ばれます) の使用。\n",
    "\n",
    "ニューラル ネットワークの研究は、初期の急速な進歩の後、1995 年頃から 2005 年まで停滞しました。これには主に 2 つの理由がありました。まず、ネットワークのトレーニングには計算コストが非常にかかります。前世紀末にはランダム アクセス メモリが豊富にありましたが、計算能力は不足していました。第二に、データセットが比較的小さかったことです。実際、1932 年の Fisher の Iris データセットは、アルゴリズムの有効性をテストするための人気のあるツールでした。 60,000 個の手書き数字を含む MNIST データセットは巨大であると考えられていました。\n",
    "\n",
    "データと計算が不足しているため、カーネル法、デシジョン ツリー、グラフィカル モデルなどの強力な統計ツールが多くのアプリケーションで優れていることが経験的に証明されています。さらに、ニューラル ネットワークとは異なり、トレーニングに数週間を必要とせず、強力な理論的保証を備えた予測可能な結果が得られました。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cbee76-a208-4f37-8aa5-9412c562668a",
   "metadata": {},
   "source": [
    "\n",
    "## ディープラーニングへの道\n",
    "\n",
    "この状況の多くは、ワールド ワイド ウェブ、オンラインで数億人のユーザーにサービスを提供する企業の出現、安価で高品質のセンサー、安価なデータ ストレージ (クライダーの法則) の普及、そして安価な計算 (ムーアの法則)。特に、ディープ ラーニングにおける計算の状況は、もともとコンピューター ゲーム用に設計された GPU の進歩によって革命をもたらしました。計算的に実行不可能と思われていたアルゴリズムやモデルが突然、適切なものになりました (逆も同様です)。これは、 :numref: `tab_intro_decade`に最もよく示されています。\n",
    "\n",
    " :データセットとコンピューターのメモリおよび計算能力の比較 :ラベル: `tab_intro_decade`\n",
    "\n",
    " |10 年|データセット|メモリ|1 秒あたりの浮動小数点計算| |:--|:-|:-|:-| |1970|100 (アイリス)|1 KB|100 KF (インテル 8080)| |1980|1 K (ボストンの住宅価格)|100 KB|1 MF (Intel 80186)| |1990|10 K (光学式文字認識)|10 MB|10 MF (Intel 80486)| |2000|10 M (Web ページ)|100 MB|1 GF (インテル コア)| |2010|10 G (広告)|1 GB|1 TF (Nvidia C2050)| |2020|1 T (ソーシャル ネットワーク)|100 GB|1 PF (Nvidia DGX-2)|\n",
    "\n",
    "ランダム アクセス メモリはデータの増加に追いついていないことに注意してください。同時に、計算​​能力の増加がデータセットの増加を上回っています。これは、統計モデルのメモリ効率を高める必要があり、コンピューティング バジェットの増加により、パラメーターの最適化により多くのコンピューター サイクルを自由に費やすことができることを意味します。その結果、機械学習と統計のスイート スポットは、(一般化された) 線形モデルとカーネル手法からディープ ニューラル ネットワークに移りました。これは、多層パーセプトロン :cite: `McCulloch.Pitts.1943` 、畳み込みニューラル ネットワーク :cite: `LeCun.Bottou.Bengio.ea.1998` 、長期短期記憶などの深層学習の主力の多くが機能する理由の 1 つでもあります。 :cite: `Hochreiter.Schmidhuber.1997` 、および Q-Learning :cite: `Watkins.Dayan.1992` 、かなりの期間比較的眠っていた後、基本的に過去 10 年間に「再発見」されました。\n",
    "\n",
    "統計モデル、アプリケーション、アルゴリズムの最近の進歩は、種の進化における急速な進歩の瞬間であるカンブリア爆発にたとえられることがあります。実際、最先端技術は、数十年前のアルゴリズムに適用された、利用可能なリソースの単なる結果ではありません。以下のリストは、研究者が過去 10 年間に大きな進歩を遂げるのに役立ったアイデアのほんの表面にすぎないことに注意してください。\n",
    "- *ドロップアウト*:cite: `Srivastava.Hinton.Krizhevsky.ea.2014`などの容量制御の新しい方法は、過剰学習の軽減に役立ちました。ここでは、トレーニング中にニューラル ネットワーク全体にノイズが注入されます (:cite: `Bishop.1995` 。\n",
    "- アテンション メカニズムは、1 世紀以上にわたり統計学を悩ませてきた 2 番目の問題、つまり学習可能なパラメータの数を増やさずにシステムのメモリと複雑さを増やす方法を解決しました。研究者は、学習可能なポインター構造としてしか見ることができないものを使用することで、洗練された解決策を発見しました (引用: `Bahdanau.Cho.Bengio.2014` )。たとえば固定次元表現での機械翻訳の場合、テキスト シーケンス全体を記憶する必要はなく、保存する必要があるのは翻訳プロセスの中間状態へのポインタだけでした。これにより、新しいシーケンスの生成を開始する前にモデルがシーケンス全体を記憶する必要がなくなったため、長いシーケンスの精度が大幅に向上しました。\n",
    "- アテンション メカニズムのみに基づいて構築された Transformer アーキテクチャ :cite: `Vaswani.Shazeer.Parmar.ea.2017`は、優れた*スケーリング*動作を実証しました。データセット サイズ、モデル サイズ、トレーニング コンピューティング量の増加に伴ってパフォーマンスが向上します :cite: `kaplan2020scaling` 。このアーキテクチャは、自然言語処理 :cite: `Devlin.Chang.Lee.ea.2018,brown2020language` 、コンピュータ ビジョン :cite: `Dosovitskiy.Beyer.Kolesnikov.ea.2021,liu2021swin`など、幅広い分野で説得力のある成功を実証しています。音声認識 :cite: `gulati2020conformer` 、強化学習 :cite: `chen2021decision` 、およびグラフ ニューラル ネットワーク :cite: `dwivedi2020generalization` 。たとえば、テキスト、画像、関節トルク、ボタンの押下などの多様なモダリティで事前トレーニングされた 1 つの Transformer で、Atari の再生、キャプション画像、チャット、ロボットの制御が可能です :cite: `reed2022generalist` 。\n",
    "- テキストシーケンスの確率をモデル化することで、*言語モデルは*他のテキストを考慮してテキストを予測できます。データ、モデル、コンピューティングのスケールアップにより、入力テキストに基づいた人間のようなテキスト生成を介して必要なタスクを実行する言語モデルの機能がますます増えています (cite: `brown2020language,rae2021scaling,hoffmann2022training,chowdhery2022palm` )。たとえば、言語モデルを人間の意図に合わせる :cite: `ouyang2022training` 、OpenAI の[ChatGPT を](https://chat.openai.com/)使用すると、ユーザーは会話形式で対話して、コードのデバッグやメモの作成などの問題を解決できます。\n",
    "- たとえば、メモリ ネットワーク :cite: `Sukhbaatar.Weston.Fergus.ea.2015`およびニューラル プログラマ インタプリタ :cite: `Reed.De-Freitas.2015`を介した多段階設計により、統計モデラーは推論への反復アプローチを記述することができました。これらのツールを使用すると、プロセッサが計算のためにメモリを変更する方法と同様に、ディープ ニューラル ネットワークの内部状態を繰り返し変更して、一連の推論の後続のステップを実行できます。\n",
    "- *深い生成モデリング*における重要な発展は、*敵対的生成ネットワーク*の発明でした:cite: `Goodfellow.Pouget-Abadie.Mirza.ea.2014` 。従来、密度推定および生成モデルの統計的手法は、適切な確率分布と、そこからサンプリングするための (多くの場合近似的な) アルゴリズムを見つけることに重点を置いていました。結果として、これらのアルゴリズムは、統計モデルに固有の柔軟性の欠如によって大きく制限されました。敵対的生成ネットワークにおける重要な革新は、サンプラーを微分可能なパラメーターを備えた任意のアルゴリズムに置き換えることでした。これらは、識別子 (事実上 2 サンプル テスト) が本物のデータと偽のデータを区別できないように調整されます。任意のアルゴリズムを使用してデータを生成できる機能により、密度推定をさまざまな手法に応用できるようになりました。疾走するシマウマの例 :cite: `Zhu.Park.Isola.ea.2017`と偽の有名人の顔 :cite: `Karras.Aila.Laine.ea.2017`は両方ともこの進歩の証拠です。アマチュアの落書き家でも、シーンのレイアウトがどのように見えるかを説明するスケッチだけを基に、フォトリアリスティックな画像を作成できます (引用: `Park.Liu.Wang.ea.2019` )。\n",
    "- さらに、拡散プロセスではランダム ノイズがデータ サンプルに徐々に追加されますが、*拡散モデル*:cite: `sohl2015deep,ho2020denoising`ノイズ除去プロセスを学習して、ランダム ノイズからデータ サンプルを徐々に構築し、拡散プロセスを逆転させます。これらは、テキストの説明に基づいてクリエイティブ アートや画像を生成するための DALL-E 2 :cite: `ramesh2022hierarchical`や Imagen :cite: `saharia2022photorealistic`など、より最近の深層生成モデルにおける敵対的生成ネットワークを置き換え始めています。\n",
    "- 多くの場合、トレーニングに使用できる大量のデータを処理するには、1 つの GPU では不十分です。過去 10 年間で、並列分散トレーニング アルゴリズムを構築する機能が大幅に向上しました。スケーラブルなアルゴリズムを設計する際の重要な課題の 1 つは、深層学習最適化の主力である確率的勾配降下法が、処理されるデータの比較的小さなミニバッチに依存していることです。同時に、バッチが小さいと GPU の効率が制限されます。したがって、1024 GPU で、たとえばバッチあたり 32 画像のミニバッチ サイズでトレーニングすると、合計で約 32000 画像のミニバッチになります。最近の研究では、最初は :citet: `Li.2017` 、続いて :citet: `You.Gitman.Ginsburg.2017`と :citet: `Jia.Song.He.ea.2018`によってサイズが 64000 観測値まで増加し、トレーニング時間が短縮されました。 ImageNet データセット上の ResNet-50 モデルを 7 分未満に短縮します。比較のために -- 当初、トレーニング時間は数日単位で測定されました。\n",
    "- 計算を並列化する能力は、*強化学習*の進歩にも貢献しており、これにより、囲碁、Atari ゲーム、Starcraft などのタスク、および物理シミュレーション (MuJoCo などを使用) などのタスクで超人的なパフォーマンスを達成するコンピューターの大幅な進歩につながりました。利用可能。 AlphaGo でこれを実現する方法の説明については、たとえば、:citet: `Silver.Huang.Maddison.ea.2016`を参照してください。一言で言えば、強化学習は、(状態、アクション、報酬) タプルが豊富にある場合に最も効果的に機能します。シミュレーションはそのような手段を提供します。\n",
    "- ディープラーニングのフレームワークは、アイデアの普及において重要な役割を果たしてきました。ニューラル ネットワーク モデリング用のオープンソース フレームワークの第 1 世代は、 [Caffe](https://github.com/BVLC/caffe) 、 [Torch](https://github.com/torch) 、および[Theano](https://github.com/Theano/Theano)で構成されていました。多くの独創的な論文がこれらのツールを使用して書かれました。現在では、これらは[TensorFlow](https://github.com/tensorflow/tensorflow) (多くの場合、高レベル API [Keras](https://github.com/keras-team/keras)経由で使用されます)、 [CNTK](https://github.com/Microsoft/CNTK) 、 [Caffe 2](https://github.com/caffe2/caffe2) 、および[Apache MXNet](https://github.com/apache/incubator-mxnet)に取って代わられています。第 3 世代のツールは、深層学習用のいわゆる*命令型*ツールで構成されています。この傾向はおそらく[Chainer](https://github.com/chainer/chainer)によって火付け役となり、Python NumPy に似た構文を使用してモデルを記述します。このアイデアは、 [PyTorch](https://github.com/pytorch/pytorch) 、MXNet の[Gluon API](https://github.com/apache/incubator-mxnet) 、および[JAX](https://github.com/google/jax)の両方で採用されました。\n",
    "\n",
    "より優れたツールを構築するシステム研究者と、より優れたニューラル ネットワークを構築する統計モデラーとの分業により、作業が大幅に簡素化されました。たとえば、線形ロジスティック回帰モデルのトレーニングは、以前は自明ではない宿題の問題であり、機械学習の新しい博士号を取得するのにふさわしいものでした。現在では、このタスクは 10 行未満のコードで実行できるようになり、プログラマーがしっかりと理解できるようになりました。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a4edc-182e-4baf-aff5-b026b35ab765",
   "metadata": {},
   "source": [
    "\n",
    "## 成功事例\n",
    "\n",
    "AI には、他の方法では達成が困難な結果をもたらしてきた長い歴史があります。たとえば、光学式文字認識を使用した郵便仕分けシステムは 1990 年代から導入されています。結局のところ、これは手書き数字の有名な MNIST データセットのソースです。銀行預金の小切手の読み取りや申請者の信用度のスコアリングにも同じことが当てはまります。金融取引は不正行為がないか自動的にチェックされます。これは、PayPal、Stripe、AliPay、WeChat、Apple、Visa、MasterCard などの多くの電子商取引支払いシステムのバックボーンを形成します。チェス用のコンピューター プログラムは数十年にわたって競争が続いています。機械学習は、インターネット上で検索、推奨、パーソナライズ、ランキングをフィードします。言い換えれば、機械学習は目に見えないようにされているにもかかわらず、広く普及しています。\n",
    "\n",
    " AI が脚光を浴びるようになったのはつい最近のことであり、その主な理由は、以前は解決が難しいと考えられていた、消費者に直接関係する問題の解決策によるものです。このような進歩の多くはディープラーニングによるものです。\n",
    "-  Apple の Siri、Amazon の Alexa、Google のアシスタントなどのインテリジェント アシスタントは、音声による質問にある程度の精度で答えることができます。これには、照明のスイッチをオンにするなどの単純なタスクから、理髪店の予約を手配したり、電話でのサポート ダイアログを提供したりするなど、より複雑なタスクが含まれます。これはおそらく、AI が私たちの生活に影響を与えていることを示す最も顕著な兆候です。\n",
    "- デジタル アシスタントの重要な要素は、音声を正確に認識する機能です。徐々に、このようなシステムの精度は、特定のアプリケーションで人間と同等の精度を達成できるまで向上しました (引用: `Xiong.Wu.Alleva.ea.2018` )。\n",
    "- 物体認識も同様に大きな進歩を遂げました。 2010 年、画像内のオブジェクトを推定することはかなり困難な作業でした。ImageNet ベンチマークでは、NEC 研究所とイリノイ大学アーバナシャンペーン校の研究者がトップ 5 のエラー率 28% を達成しました :cite: `Lin.Lv.Zhu.ea.2010` 。 2017 年までに、このエラー率は 2.25% に減少しました:cite: `Hu.Shen.Sun.2018` 。同様に、鳥の識別や皮膚がんの診断でも驚くべき結果が達成されています。\n",
    "- ゲームの腕前は人間の知性を測る尺度として使われていました。時間差強化学習を使用してバックギャモンをプレイするためのプログラムである TD-Gammon から始まり、アルゴリズムと計算の進歩により、幅広い用途のアルゴリズムが誕生しました。バックギャモンとは異なり、チェスにははるかに複雑な状態空間と一連のアクションがあります。 DeepBlue は、大規模な並列処理、専用ハードウェア、ゲーム ツリーによる効率的な検索を使用して Garry Kasparov を破りました:cite: `Campbell.Hoane-Jr.Hsu.2002` 。 Go は状態空間が巨大であるため、さらに困難です。 AlphaGo は、深層学習とモンテカルロ ツリー サンプリングを組み合わせて使用​​し、2015 年に人間と同等に達しました (cite: `Silver.Huang.Maddison.ea.2016` )。ポーカーにおける課題は、状態空間が大きく、部分的にしか観察されない (対戦相手のカードがわからない) ということでした。 Libratus は、効率的に構築された戦略を使用してポーカーで人間のパフォーマンスを上回りました :cite: `Brown.Sandholm.2017` 。\n",
    "-  AI の進歩を示すもう 1 つの兆候は、自動運転車やトラックの出現です。完全な自律性はまだ手の届くところにありませんが、Tesla、NVIDIA、Waymo などの企業が少なくとも部分的な自律性を可能にする製品を出荷するなど、この方向では素晴らしい進歩が見られます。完全自動運転が非常に難しいのは、適切な運転には、認識し、推論し、ルールをシステムに組み込む能力が必要であるためです。現在、深層学習は主にこれらの問題のコンピューター ビジョンの側面で使用されています。残りはエンジニアによって大幅に調整されます。\n",
    "\n",
    "これは、機械学習の影響力のあるアプリケーションのほんの表面をなぞっただけです。たとえば、ロボット工学、物流、計算生物学、素粒子物理学、天文学などの最近の目覚ましい進歩は、少なくとも部分的には機械学習のおかげです。このように、機械学習はエンジニアや科学者にとって普遍的なツールになりつつあります。\n",
    "\n",
    " AI に関する非技術的な記事では、来るべき AI 黙示録と*特異点*の妥当性に関する疑問が頻繁に提起されています。恐怖は、何らかの形で機械学習システムが知覚を持ち、プログラマーから独立して人間の生活に直接影響を与える意思決定を行うようになるのではないかということです。 AI はすでにある程度、人間の生活に直接的な影響を与えています。信用度は自動的に評価され、自動操縦装置は主に車両を操縦し、保釈を許可するかどうかの決定には統計データが入力として使用されます。もっと軽薄なことに、Alexa にコーヒーマシンのスイッチを入れるように頼むことができます。\n",
    "\n",
    "幸いなことに、私たちは人間の創造者を意図的に操作できるような知覚を持った AI システムからは程遠いです。まず、AI システムは、特定の目標指向の方法で設計、トレーニング、導入されます。彼らの行動は一般的な知能であるかのような錯覚を与えるかもしれませんが、設計の基礎となるのはルール、ヒューリスティック、統計モデルの組み合わせです。第二に、現時点では、*汎用人工知能*用のツールは、一般的なタスクを解決しながら、自身を改善し、自らを推論し、自身のアーキテクチャを変更、拡張、改善できるツールがまったく存在しません。\n",
    "\n",
    "それよりも差し迫った懸念は、AI が私たちの日常生活でどのように使用されているかです。トラック運転手や店員が行う多くの単純作業は自動化できる可能性があり、自動化される可能性があります。ファームロボットは有機農業のコストを削減する可能性が高いが、収穫作業も自動化するだろう。トラック運転手や店員は多くの国で最も一般的な仕事の一部であるため、産業革命のこの段階は社会の広範囲に重大な影響を与える可能性があります。さらに、統計モデルは、注意せずに適用すると、人種、性別、年齢の偏見につながる可能性があり、結果的な意思決定を促進するために自動化された場合、手続きの公平性について合理的な懸念が生じる可能性があります。これらのアルゴリズムは注意して使用することが重要です。今日私たちが知っていることから、このことは、悪意のある超知性が人類を滅ぼす可能性よりもはるかに差し迫った懸念を私たちに与えます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3657c862-0097-41d0-b0f6-e7012c4626c2",
   "metadata": {},
   "source": [
    "\n",
    "## ディープラーニングの本質\n",
    "\n",
    "これまで、機械学習について幅広く説明してきました。ディープラーニングは、多層のニューラルネットワークに基づくモデルに関係する機械学習のサブセットです。これは、モデルが多くの*層*の変換を学習するという意味で、まさに*奥深い*ものです。これは狭いように聞こえるかもしれませんが、ディープ ラーニングは、目まぐるしいほどのモデル、テクニック、問題定式化、およびアプリケーションを生み出しました。深さの利点を説明するために多くの直観が開発されてきました。おそらく、すべての機械学習には多くの計算層があり、最初の層は特徴処理ステップで構成されます。深層学習の違いは、多くの表現層のそれぞれで学習される操作がデータから共同して学習されることです。\n",
    "\n",
    "これまで議論してきた問題、たとえば、生の音声信号からの学習、画像の生のピクセル値、または任意の長さの文とそれに対応する外国語間のマッピングなどは、深層学習が優れており、従来の手法が行き詰まる問題です。これらの多層モデルは、以前のツールでは不可能な方法で低レベルの知覚データに対処できることが判明しました。おそらく、深層学習手法の最も重要な共通点は、*エンドツーエンドのトレーニング*です。つまり、個別に調整されたコンポーネントに基づいてシステムを組み立てるのではなく、システムを構築してから、それらのパフォーマンスを共同で調整します。たとえば、コンピューター ビジョンでは、科学者は*特徴量エンジニアリング*のプロセスを機械学習モデルの構築プロセスから分離していました。 Canny エッジ検出器 :cite: `Canny.1987`と Lowe の SIFT 特徴抽出器 :cite: `Lowe.2004` 、画像を特徴ベクトルにマッピングするアルゴリズムとして 10 年以上にわたって最高の地位に君臨しました。昔は、これらの問題に機械学習を適用する上で重要な部分は、データを浅いモデルに適した何らかの形式に変換する手動で設計された方法を考え出すことで構成されていました。残念ながら、アルゴリズムによって自動的に実行される何百万もの選択に対する一貫した評価と比較すると、人間が創意工夫によって達成できることはごくわずかです。深層学習が引き継がれると、これらの特徴抽出器は自動的に調整されたフィルターに置き換えられ、優れた精度が得られました。\n",
    "\n",
    "したがって、深層学習の重要な利点の 1 つは、従来の学習パイプラインの最後にある浅いモデルだけでなく、労働集約的な特徴量エンジニアリングのプロセスも置き換えることです。さらに、ドメイン固有の前処理の多くを置き換えることにより、ディープ ラーニングは、これまでコンピューター ビジョン、音声認識、自然言語処理、医療情報学、その他のアプリケーション分野を分けていた境界線の多くを排除し、多様な問題に取り組むための統一されたツール セットを提供します。問題。\n",
    "\n",
    "エンドツーエンドのトレーニングを超えて、私たちはパラメトリック統計記述から完全なノンパラメトリック モデルへの移行を経験しています。データが不足している場合、有用なモデルを取得するには、現実に関する単純化された仮定に頼る必要があります。データが豊富な場合は、データによりよく適合するノンパラメトリック モデルに置き換えることができます。これは、ある意味、前世紀半ばにコンピューターの利用が可能になった物理学の進歩を反映しています。電子がどのように動作するかのパラメトリック近似を手作業で解くのではなく、関連する偏微分方程式の数値シミュレーションに頼ることができるようになりました。これにより、多くの場合説明可能性が犠牲になるものの、はるかに正確なモデルが実現しました。\n",
    "\n",
    "以前の研究とのもう 1 つの違いは、次善の解を受け入れること、非凸非線形最適化問題を扱うこと、証明する前に物事を試してみる意欲があることです。統計的問題を扱う際に新たに発見された経験主義と、人材の急速な流入が相まって、多くの場合、数十年にわたって存在したツールの修正や再発明という犠牲を払ってではあるが、実用的なアルゴリズムの急速な進歩につながった。\n",
    "\n",
    "最終的に、ディープ ラーニング コミュニティは、学術や企業の境界を越えてツールを共有し、多くの優れたライブラリ、統計モデル、訓練されたネットワークをオープンソースとしてリリースすることに誇りを持っています。この精神に基づいて、この本を構成するノートは自由に配布および使用できます。私たちは、誰もがディープ ラーニングについて学ぶためのアクセスの障壁を下げるために懸命に努力してきました。そして、読者の皆様がその恩恵を受けることを願っています。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615e510",
   "metadata": {},
   "source": [
    "\n",
    "## まとめ\n",
    "\n",
    "機械学習は、コンピューター システムが経験 (多くの場合はデータ) を活用して特定のタスクのパフォーマンスを向上させる方法を研究します。統計、データマイニング、最適化のアイデアを組み合わせています。多くの場合、AI ソリューションを実装する手段として使用されます。機械学習の一種である表現学習は、データを表現する適切な方法を自動的に見つける方法に焦点を当てています。多くの層の変換を学習することによるマルチレベル表現学習として、ディープ ラーニングは、従来の機械学習パイプラインの最後にある浅いモデルだけでなく、労働集約的な特徴量エンジニアリングのプロセスも置き換えます。ディープラーニングにおける最近の進歩の多くは、安価なセンサーやインターネット規模のアプリケーションから得られる豊富なデータと、主に GPU を介した計算の大幅な進歩によって引き起こされています。さらに、効率的な深層学習フレームワークの利用により、高いパフォーマンスを得る上で重要な要素であるシステム全体の最適化の設計と実装が大幅に容易になりました。\n",
    "\n",
    "## 演習\n",
    "1. 現在作成しているコードのどの部分が「学習」できる可能性がありますか?つまり、コード内で行われた設計の選択を学習して自動的に決定することによって改善できる可能性がありますか?コードにはヒューリスティックな設計の選択肢が含まれていますか?望ましい動作を学習するにはどのようなデータが必要になるでしょうか?\n",
    "1. あなたが遭遇した問題のうち、解決方法の例はたくさんあるものの、自動化する具体的な方法が存在しないものはどれですか?これらは、深層学習の使用の主な候補となる可能性があります。\n",
    "1. アルゴリズム、データ、計算の間の関係を説明します。データの特性と現在利用可能な計算リソースは、さまざまなアルゴリズムの適切性にどのような影響を与えるのでしょうか?\n",
    "1. エンドツーエンドのトレーニングが現在デフォルトのアプローチではないが、役立つ可能性がある設定をいくつか挙げてください。\n",
    "\n",
    "[ディスカッション](https://discuss.d2l.ai/t/22)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
